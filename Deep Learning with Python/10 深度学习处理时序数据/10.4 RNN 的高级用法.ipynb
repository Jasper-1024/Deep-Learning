{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "10.4 RNN 的高级用法\r\n",
    "\r\n",
    "到目前为止,我们已经学过的内容\r\n",
    "\r\n",
    "- 什么是 RNN 及它如何工作\r\n",
    "- 什么是 ltsm 及 ltsm 比简单 rnn 更好\r\n",
    "- 如何使用 keras 的 rnn 层处理时序数据.\r\n",
    "\r\n",
    "接下来我们会学习 keras rnn 的高级特性,这可以帮助我们的模型达到更好的效果.\r\n",
    "\r\n",
    "- 循环 dropout: 在 rnn 层应用 dropout.\r\n",
    "- 堆叠循环层: 提高模型的容量和表现力,代价是更高的计算消耗.\r\n",
    "- 双向 RNN: 将相同的信息正向/反向送入模型,提高精读缓解遗忘问题.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 循环 dropout 缓解过拟合\r\n",
    "\r\n"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('tf')"
  },
  "interpreter": {
   "hash": "aac46f597da82ce9618f0e6f094e6d401f1ab16d9be89acf77ce1dd63d67a333"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}