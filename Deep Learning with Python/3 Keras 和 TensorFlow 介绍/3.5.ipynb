{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 使用 tensorflow\r\n",
    "\r\n",
    "从前例可以看出训练神经网络实际上是在两个层次上进行.\r\n",
    "\r\n",
    "低级别层次上训练神经网络实际上是对张量的各种操作,如果用 tensorflow 的 api 说明\r\n",
    "\r\n",
    "- 张量,包括存储网络状态的特殊张量.\r\n",
    "- 张量操作,像是张量的加减 relu matmul\r\n",
    "- 反向传播(backpropagation),一种链式计算梯度的方法.(tensorflow 中使用 GradientTape 类处理)\r\n",
    "\r\n",
    "高层次上以 keras 的 api 说明\r\n",
    "\r\n",
    "- layers,许多的层组合成一个神经网络模型 model\r\n",
    "- 损失函数,定义了训练中的反馈信号.\r\n",
    "- 优化器,定义了训练中的参数更新方法,如何进行学习.\r\n",
    "- 指标,用来评估模型,例如模型的准确度等.\r\n",
    "- 循环训练,执行小批量的随机梯度下降.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 张量变量\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import tensorflow as tf\r\n",
    "x = tf.ones(shape=(2,1))\r\n",
    "print(x)\r\n",
    "x = tf.zeros(shape=(2,1))\r\n",
    "print(x)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor(\n",
      "[[1.]\n",
      " [1.]], shape=(2, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.]\n",
      " [0.]], shape=(2, 1), dtype=float32)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "初始化 shape(2,1) 的张量,全1 或 全0\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "x = tf.random.normal(shape=(3, 1), mean=0., stddev=1.)\r\n",
    "print(x)\r\n",
    "\r\n",
    "x = tf.random.uniform(shape=(3, 1), minval=0., maxval=1.)\r\n",
    "print(x)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor(\n",
      "[[-1.3895277 ]\n",
      " [-0.12083016]\n",
      " [ 0.7774914 ]], shape=(3, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.96545494]\n",
      " [0.168015  ]\n",
      " [0.59226465]], shape=(3, 1), dtype=float32)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "随机填充值\r\n",
    "\r\n",
    "- `tf.random.normal(shape=(3, 1), mean=0., stddev=1.)` 是从平均数0和标准差1中产生随机数.等同于 `np.random.normal(size=(3, 1), loc=0.,.scale=1.)`\r\n",
    "- `tf.random.uniform(shape=(3, 1), minval=0., maxval=1.)` 是从0到1的均匀分布中产生随机数.等同于 `np.random.uniform(size=(3, 1), low=0., high=1.)`\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import numpy as np\r\n",
    "x = np.ones(shape=(2, 2))\r\n",
    "x[0, 0] = 0."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "x = tf.ones(shape=(2, 2))\r\n",
    "x[0, 0] = 0."
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10632/2354548564.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**tensorflow 创建的数组是不可变的**,而 numpy 创建的数组是可变的.\r\n",
    "\r\n",
    "tensorflow 中创建可以修改的张量是靠 tf.Variable 类,使用 tf.Variable 需要提供 initial_value (张量初始值).\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "v = tf.Variable(initial_value=tf.random.normal(shape=[3, 1], mean=0, stddev=1))\r\n",
    "v"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(3, 1) dtype=float32, numpy=\n",
       "array([[-1.4414899],\n",
       "       [-0.6730556],\n",
       "       [ 1.8196104]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "创建一个 tf.Variable\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "v.assign(tf.ones((3, 1)))\r\n",
    "print(v)\r\n",
    "v[0, 0].assign(3.)\r\n",
    "print(v)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<tf.Variable 'Variable:0' shape=(3, 1) dtype=float32, numpy=\n",
      "array([[1.],\n",
      "       [1.],\n",
      "       [1.]], dtype=float32)>\n",
      "<tf.Variable 'Variable:0' shape=(3, 1) dtype=float32, numpy=\n",
      "array([[3.],\n",
      "       [1.],\n",
      "       [1.]], dtype=float32)>\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "修改 tf.Variable 需要通过 assign 方法.\r\n",
    "\r\n",
    "修改子集也是通过 assign 方法.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "v.assign_add(tf.ones((3,1)))\r\n",
    "print(v)\r\n",
    "\r\n",
    "v.assign_sub(tf.ones((3,1)))\r\n",
    "print(v)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<tf.Variable 'Variable:0' shape=(3, 1) dtype=float32, numpy=\n",
      "array([[4.],\n",
      "       [2.],\n",
      "       [2.]], dtype=float32)>\n",
      "<tf.Variable 'Variable:0' shape=(3, 1) dtype=float32, numpy=\n",
      "array([[3.],\n",
      "       [1.],\n",
      "       [1.]], dtype=float32)>\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "assign_add 相当于 +=\r\n",
    "\r\n",
    "assign_sub 相当于 -=\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 张量运算\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "a = tf.ones((2, 2))\r\n",
    "b = tf.square(a)\r\n",
    "print(b)\r\n",
    "c = tf.sqrt(a)\r\n",
    "print(c)\r\n",
    "d = b + c\r\n",
    "print(d)\r\n",
    "e = tf.matmul(a, b)\r\n",
    "print(e)\r\n",
    "e *= d\r\n",
    "print(e)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor(\n",
      "[[1. 1.]\n",
      " [1. 1.]], shape=(2, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.99999994 0.99999994]\n",
      " [0.99999994 0.99999994]], shape=(2, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[2. 2.]\n",
      " [2. 2.]], shape=(2, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[2. 2.]\n",
      " [2. 2.]], shape=(2, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[4. 4.]\n",
      " [4. 4.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "张量运算\r\n",
    "\r\n",
    "- tf.square 平方\r\n",
    "- tf.sqrt 平方根\r\n",
    "- `+` 张量相加\r\n",
    "- `tf.matmul` 张量乘法\r\n",
    "- `*` 张量逐元素相乘\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 再探 GradientTape\r\n",
    "\r\n",
    "从上面的张量运算来看,tensorflow 做了和 numpy 非常相似的工作.但是在 tensorflow 有一条是 numpy 做不到的,tensorflow 可以方便计算任何可微表达式的梯度.只要借助 GradientTape api.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "input_var = tf.Variable(initial_value=3.)\r\n",
    "\r\n",
    "with tf.GradientTape() as tape:\r\n",
    "    result = tf.square(input_var)\r\n",
    "gradient = tape.gradient(result, input_var)\r\n",
    "\r\n",
    "print(gradient)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor(6.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "最常见计算梯度的形式 `gradients = tape.gradient(loss, weights)`\r\n",
    "\r\n",
    "第二章,我们看到过 GradientTape 的输入可以是单一输入或者输入列表.可以输入常量或者更高维的张量.\r\n",
    "\r\n",
    "到现在为止我们看到输入 tape.gradient() 都是由 tensorflow 生成的变量.但是实际上 tape.gradient() 可以接收任意的张量输入.但是默认情况下只有张量是可训练张量(trainable variables)时才会被跟踪??,对于冻结张量(常量)需要手动通过 `tape.watch()` 设置跟踪.(??有点云里雾里??)\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "input_const = tf.constant(3.)\r\n",
    "\r\n",
    "with tf.GradientTape() as tape:\r\n",
    "    tape.watch(input_const)\r\n",
    "    result = tf.square(input_const)\r\n",
    "\r\n",
    "gradient = tape.gradient(result, input_const)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "计算常量张量的梯度需要 `tape.watch` 设置跟踪.\r\n",
    "\r\n",
    "计算梯度是非常消耗资源的事情,不可能预先跟踪所有张量.为了避免资源浪费,tensorflow 默认只监视可训练的张量(trainable variables),因为通常需要计算梯度的就是这些张量.\r\n",
    "\r\n",
    "除了计算梯度以外,我们还可以计算梯度的梯度,物理学类比的化是计算速度,再计算加速度.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "time = tf.Variable(0.)\r\n",
    "with tf.GradientTape() as outer_tape:\r\n",
    "    with tf.GradientTape() as inner_tape:\r\n",
    "        position = 4.9 * time**2 # ** 是乘方\r\n",
    "    speed = inner_tape.gradient(position, time)\r\n",
    "acceleration = outer_tape.gradient(speed, time)\r\n",
    "print(position)\r\n",
    "print(speed)\r\n",
    "print(acceleration)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(9.8, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "时间和位置: $p = 4.9 * time^2$\r\n",
    "\r\n",
    "时间和速度: $s = 4.9 * 2 *time$\r\n",
    "\r\n",
    "时间和加速度: $a = 4.9 *2$\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 端到端的 tensorflow 的分类器\r\n"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('tf': venv)"
  },
  "interpreter": {
   "hash": "aac46f597da82ce9618f0e6f094e6d401f1ab16d9be89acf77ce1dd63d67a333"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}