{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前排提醒: 纯机翻!! 不确定会不会重写"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本章包括\n",
    "\n",
    "- 重要启示\n",
    "- 深度学习局限\n",
    "- 深度学习、机器学习和人工智能的未来可能方向\n",
    "- 进一步学习和在实践中应用你的技能的资源"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你已经快到本书的结尾了。这最后一章将总结和回顾核心概念，同时也将扩大你的视野，超越你目前所学的知识。成为一名有效的人工智能从业者是一个旅程，而读完本书只是你迈出的第一步。我想确保你能意识到这一点，并为你自己迈出这段旅程的下一步做好准备。\n",
    "\n",
    "我们先来看看你应该从这本书中获得什么，这是一个鸟瞰图。这应该能唤起你对所学到的一些概念的记忆。接下来，我们将对深度学习的一些关键限制进行概述。为了适当地使用一个工具，你不仅应该了解它能做什么，而且还应该知道它不能做什么。最后，我将对深度学习、机器学习和人工智能的未来发展提出一些推测性想法。如果你想进入基础研究，这对你来说应该特别有意思。本章最后列出了一份简短的资源和策略清单，以便进一步学习机器学习，并跟上新的进展。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 关键概念回顾\n",
    "\n",
    "AI > 机器学习 > 深度学习\n",
    "\n",
    "深度学习是机器学习的众多分支之一，其中的模型是一长串的几何变换，一个接一个地应用。这些操作被结构化为称为层的模块：深度学习模型通常是层的堆叠，或者更普遍的是层的图形。这些层的参数是由权重决定的，而权重是在训练期间学到的参数。模型的知识存储在其权重中，而学习的过程包括为这些权重寻找 \"好的值\"--使损失函数最小化的值。由于所考虑的几何变换链是可微调的，更新权重以最小化损失函数是通过梯度下降有效完成的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 深度学习特殊性\n",
    "\n",
    "第三次人工智能革命的核心\n",
    "\n",
    "我对深度学习特别乐观，因为即使我们在未来十年内没有进一步的技术进步，将现有的算法部署到每一个适用的问题上，对大多数行业来说都会改变游戏规则。深度学习是一场不折不扣的革命，由于对资源和人员的指数级投资，目前的进展速度快得令人难以置信。在我看来，未来是光明的，尽管短期的期望有些过于乐观；将深度学习的潜力完全发挥出来，可能需要几十年的时间。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 思考深度学习的问题\n",
    "\n",
    "深度学习最令人惊讶的地方在于它是如此简单。十年前，没有人想到我们会通过使用用梯度下降训练的简单参数模型在机器感知问题上取得如此惊人的结果。现在，事实证明，你所需要的只是在足够多的例子上用梯度下降训练的足够大的参数模型。正如费曼曾经对宇宙说过的那样，\"它并不复杂，只是有很多。\n",
    "\n",
    "在深度学习中，所有东西都是一个矢量，也就是说，所有东西都是几何空间中的一个点。模型输入（文本、图像等）和目标首先被矢量化：变成一个初始输入矢量空间和目标矢量空间。深度学习模型中的每一层都对通过它的数据进行简单的几何变换。模型中的层链一起形成了一个复杂的几何变换，被分解成一系列简单的变换。这个复杂的转换试图将输入空间映射到目标空间，一次一个点。这个转换的参数是各层的权重，这些权重根据模型目前的表现而迭代更新。这种几何变换的一个关键特征是，它必须是可微的，这是我们能够通过梯度下降学习其参数所需要的。直观地说，这意味着从输入到输出的几何变形必须是平滑和连续的--这是一个重要的约束条件。\n",
    "\n",
    "将这种复杂的几何变换应用于输入数据的整个过程可以通过想象一个人试图解开一个纸球来进行三维可视化：皱巴巴的纸球是模型开始的输入数据的流形。人在纸球上的每个动作都类似于由一个层操作的简单几何变换。完整的解皱手势序列是整个模型的复杂变换。深度学习模型是对高维数据的复杂流形进行解溃的数学机器。\n",
    "\n",
    "这就是深度学习的神奇之处：把意义变成矢量，变成几何空间，然后逐步学习复杂的几何变换，把一个空间映射到另一个空间。你所需要的是具有足够高维度的空间，以便捕捉原始数据中发现的全部关系。\n",
    "\n",
    "整个事情取决于一个单一的核心理念：意义来自于事物之间的配对关系（语言中的单词之间，图像中的像素之间，等等），这些关系可以通过距离函数来捕捉。但是请注意，大脑是否通过几何空间来实现意义是一个完全独立的问题。从计算的角度看，矢量空间是有效的，但可以很容易地设想出不同的智能数据结构--特别是图。神经网络最初是从使用图作为编码意义的方式的想法中产生的，这就是为什么它们被命名为神经网络；周围的研究领域曾经被称为连接主义。如今，\"神经网络 \"这个名字的存在完全是出于历史原因--这是一个极具误导性的名字，因为它们既不是神经，也不是网络。特别是，神经网络与大脑几乎没有任何关系。一个更合适的名字应该是分层表征学习或分层表征学习，甚至可能是深微分模型或链式几何变换，以强调连续几何空间操作是其核心。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 关键性技术\n",
    "\n",
    "目前正在展开的技术革命并不是从任何单一的突破性发明开始的。相反，像其他任何革命一样，它是大量有利因素积累的产物--起初是缓慢的，然后是突然的。在深度学习的案例中，我们可以指出以下关键因素。\n",
    "\n",
    "渐进式的算法创新，先是分布在20年里（从反向传播开始），然后随着2012年后更多的研究工作被投入到深度学习中而越来越快。\n",
    "\n",
    "大量感知数据的可用性，这是实现在足够大的数据上训练的足够大的模型就是我们所需要的一个条件。这又是消费互联网的兴起和摩尔定律应用于存储介质的副产品。\n",
    "    \n",
    "以低廉的价格获得快速、高度并行的计算硬件，特别是英伟达公司生产的GPU--首先是游戏GPU，然后是为深度学习设计的芯片。早期，英伟达首席执行官黄仁勋注意到了深度学习的热潮，并决定将公司的未来押在这上面--这得到了巨大的回报。\n",
    "\n",
    "一个复杂的软件层堆叠，使人类可以使用这种计算能力：CUDA语言，像TensorFlow这样的框架，可以进行自动区分，还有Keras，它使大多数人都可以使用深度学习。\n",
    "\n",
    "在未来，深度学习不会只被专家--研究人员、研究生和有学术背景的工程师使用，它将成为每个开发者的工具箱中的工具，就像今天的网络技术一样。每个人都需要建立智能应用程序：就像今天每个企业都需要一个网站一样，每个产品都将需要智能地理解用户生成的数据。要实现这一未来，我们需要建立一些工具，使深度学习从根本上易于使用，并使任何具有基本编码能力的人都能使用。Keras是朝着这个方向迈出的第一个重要步骤。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 通用机器学习工作流程\n",
    "\n",
    "拥有一个极其强大的工具来创建将任何输入空间映射到任何目标空间的模型是非常好的，但是机器学习工作流程的困难部分往往是设计和训练这种模型之前的一切（对于生产模型来说，还有之后的事情）。了解问题领域，以便能够确定在什么数据的情况下试图预测什么，以及如何衡量成功，是任何机器学习成功应用的先决条件，而这并不是像Keras和TensorFlow这样的高级工具可以帮助你的。作为提醒，下面是第六章中描述的典型机器学习工作流程的快速总结。\n",
    "\n",
    "定义问题：有哪些数据可用，你想预测什么？你是否需要收集更多的数据，或者雇人对数据集进行人工标注？\n",
    "    \n",
    "确定一种方法来可靠地衡量你的目标是否成功。对于简单的任务，这可能是预测的准确性，但在许多情况下，这将需要复杂的、特定领域的指标。\n",
    "\n",
    "准备好你将用来评估你的模型的验证过程。特别是，你应该定义一个训练集、一个验证集和一个测试集。验证集和测试集的标签不应该泄漏到训练数据中：例如，对于时间预测，验证和测试数据应该是训练数据的后置。\n",
    "\n",
    "通过将数据转化为向量，并以使其更容易被神经网络接近的方式进行预处理（归一化，等等）。\n",
    "\n",
    "开发出第一个模型，击败一个微不足道的常识性基线，从而证明机器学习可以在你的问题上发挥作用。这不一定是事实。\n",
    "\n",
    "通过调整超参数和增加正则化，逐渐完善你的模型结构。只根据验证数据的性能进行修改，而不是测试数据或训练数据。记住，你应该让你的模型过度拟合（从而确定一个比你需要的更大的模型能力水平），然后才开始增加正则化或缩小你的模型。在转动超参数时要小心验证集的过度拟合：你的超参数最终可能会对验证集进行过度专业化处理。避免这种情况是拥有一个单独的测试集的目的!\n",
    "\n",
    "在生产中部署你的最终模型--作为一个网络API，作为JavaScript或C++应用程序的一部分，在一个嵌入式设备上，等等。不断监测其在真实世界数据上的表现，并使用你的发现来完善模型的下一次迭代。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 关键网络架构\n",
    "\n",
    "你应该熟悉的四个系列的网络架构是密集连接网络、卷积网络、递归网络和变形器。每种类型的模型都是针对特定的输入模式的：网络架构编码了关于数据结构的假设：一个假设空间，在这个空间中寻找一个好的模型。一个给定的架构是否能在一个给定的问题上发挥作用，完全取决于数据结构和网络架构的假设之间的匹配。\n",
    "\n",
    "这些不同的网络类型可以很容易地被组合起来，以实现更大的多模态模型，就像你把乐高积木组合起来一样。在某种程度上，深度学习层是信息处理的乐高积木。下面是对输入模式和适当的网络架构之间的映射的快速概述。\n",
    "\n",
    "- 矢量数据 - 密集连接的模型（密集层）。\n",
    "- 图像数据--二维卷积网络。\n",
    "- 序列数据--用于时间序列的网络，或用于离散序列（如词的序列）的变形器。一维CNN也可用于翻译不变的连续序列数据，如鸟鸣波形。\n",
    "- 视频数据--要么是3D convnets（如果你需要捕捉运动效果），要么是帧级2D convnet的组合，用于特征提取，然后是序列处理模型。\n",
    "- 体积数据--三维卷积网。\n",
    "\n",
    "现在，让我们快速回顾一下每个网络架构的特点。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 密集网络\n",
    "\n",
    "密集连接网络是密集层的堆叠，旨在处理矢量数据（其中每个样本是数字或分类属性的矢量）。这样的网络没有假定输入特征的具体结构：它们被称为密集连接，因为密集层的单元与每一个其他单元都相连。该层试图映射任何两个输入特征之间的关系；这与二维卷积层不同，例如，它只关注局部关系。\n",
    "\n",
    "密集连接的网络最常用于分类数据（例如，输入特征是属性列表），如第四章中使用的波士顿住房价格数据集。它们也被用作大多数网络的最终分类或回归阶段。例如，第8章中涉及的convnets通常以一个或两个Dense层结束，第10章中的递归网络也是如此。\n",
    "\n",
    "记住：要进行二进制分类，用一个具有单一单元和sigmoid激活的Dense层来结束你的层堆，并使用binary_crossentropy作为损失。你的目标应该是0或1。\n",
    "\n",
    "```py\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "inputs = keras.Input(shape=(num_input_features,))\n",
    "x = layers.Dense(32, activation=\"relu\")(inputs)\n",
    "x = layers.Dense(32, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要进行单标签分类（每个样本只有一个类别，没有更多的类别），用一个密集层来结束你的层栈，该层的单元数等于类别数，并使用softmax激活。如果你的目标是单热编码的，使用categorical_crossentropy作为损失；如果是整数，使用sparse_categorical_crossentropy。\n",
    "\n",
    "```py\n",
    "inputs = keras.Input(shape=(num_input_features,))\n",
    "x = layers.Dense(32, activation=\"relu\")(inputs)\n",
    "x = layers.Dense(32, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要进行多标签分类（每个样本可以有几个类别），在层的堆叠中，用一个密集层来结束，其单元数等于类别数，并使用sigmoid激活，并使用二元交叉熵作为损失。你的目标应该是k-hot编码的。\n",
    "\n",
    "```py\n",
    "inputs = keras.Input(shape=(num_input_features,))\n",
    "x = layers.Dense(32, activation=\"relu\")(inputs)\n",
    "x = layers.Dense(32, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(num_classes, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要对一个连续值的向量进行回归，用一个密集层来结束你的堆栈，该层的单元数等于你要预测的值的数量（通常是单个值，如房子的价格），并且没有激活。各种损失可用于回归--最常见的是均方误差（MSE）。\n",
    "\n",
    "```py\n",
    "inputs = keras.Input(shape=(num_input_features,))\n",
    "x = layers.Dense(32, activation=\"relu\")(inputs)\n",
    "x = layers.Dense(32, activation=\"relu\")(x)\n",
    "outputs layers.Dense(num_values)(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"mse\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 卷积网络\n",
    "\n",
    "卷积层通过对输入张量中的不同空间位置（斑块）应用相同的几何变换来观察空间上的局部模式。这导致了表征的翻译不变性，使卷积层具有很高的数据效率和模块化。这个想法适用于任何维度的空间：一维（连续序列），二维（图像），三维（体积），等等。你可以用Conv1D层来处理序列，用Conv2D层来处理图像，用Conv3D层来处理体积。作为卷积层的一个更精简、更有效的替代品，你也可以使用深度可分离的卷积层，比如SeparableConv2D。\n",
    "\n",
    "Convn网络，或称卷积网络，由卷积层和最大集合层堆叠而成。池化层让你对数据进行空间降样，这是为了在特征数量增长时将特征图保持在一个合理的大小，并允许后续的卷积层 \"看到 \"更大的输入空间范围。Convnets通常以Flatten操作或全局池化层结束，将空间特征图变成向量，然后由密集层实现分类或回归。\n",
    "\n",
    "下面是一个典型的图像分类网络（本例中是分类），利用SeparableConv2D层。\n",
    "\n",
    "```py\n",
    "inputs = keras.Input(shape=(height, width, channels))\n",
    "x = layers.SeparableConv2D(32, 3, activation=\"relu\")(inputs)\n",
    "x = layers.SeparableConv2D(64, 3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "x = layers.SeparableConv2D(64, 3, activation=\"relu\")(x)\n",
    "x = layers.SeparableConv2D(128, 3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "x = layers.SeparableConv2D(64, 3, activation=\"relu\")(x)\n",
    "x = layers.SeparableConv2D(128, 3, activation=\"relu\")(x)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(32, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\")\n",
    "```\n",
    "\n",
    "当构建一个非常深入的convnet时，通常会添加批量归一化层以及残差连接--这两种架构模式有助于梯度信息在网络中顺利流动。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 递归网络\n",
    "\n",
    "递归神经网络（RNN）的工作方式是一次处理一个时间段的输入序列，并在整个过程中保持一个状态（一个状态通常是一个向量或一组向量）。在感兴趣的模式不受时间转换影响的序列中（例如，最近的过去比遥远的过去更重要的时间序列数据），它们应该优先于一维信念网络使用。\n",
    "\n",
    "在Keras中，有三个RNN层可用。SimpleRNN、GRU和LSTM。对于大多数实际目的，你应该使用GRU或LSTM。LSTM是两者中更强大的，但也更昂贵；你可以认为GRU是它的一个更简单、更便宜的替代品。\n",
    "\n",
    "为了将多个RNN层堆叠在一起，堆叠中最后一层之前的每一层都应该返回其输出的完整序列（每个输入时间步长将对应一个输出时间步长）；如果你没有进一步堆叠任何RNN层，那么通常只返回最后的输出，其中包含整个序列的信息。\n",
    "\n",
    "下面是一个用于矢量序列二进制分类的单一RNN层。\n",
    "\n",
    "```py\n",
    "inputs = keras.Input(shape=(num_timesteps, num_features))\n",
    "x = layers.LSTM(32)(inputs)\n",
    "outputs = layers.Dense(num_classes, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "这是一个堆叠的RNN层，用于向量序列的二进制分类。\n",
    "\n",
    "```py\n",
    "inputs = keras.Input(shape=(num_timesteps, num_features))\n",
    "x = layers.LSTM(32, return_sequences=True)(inputs)\n",
    "x = layers.LSTM(32, return_sequences=True)(x)\n",
    "x = layers.LSTM(32)(x)\n",
    "outputs = layers.Dense(num_classes, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 变换器\n",
    "\n",
    "变换器查看一组向量（如单词向量），并利用神经注意力将每个向量转化为一个表示，该表示了解该组中其他向量所提供的背景。当有关集合是一个有序的序列时，你也可以利用位置编码来创建Transformers，它可以考虑到全局上下文和单词顺序，能够比RNN或1D convnets更有效地处理长文本段落。\n",
    "\n",
    "变换器可用于任何集合处理或序列处理任务，包括文本分类，但它们尤其擅长序列到序列的学习，如将源语言的段落翻译成目标语言。\n",
    "\n",
    "一个序列到序列的转换器由两部分组成。\n",
    "\n",
    "- 一个TransformerEncoder，将输入矢量序列转化为上下文感知的、顺序感知的输出矢量序列。\n",
    "- 一个TransformerDecoder，它接收TransformerDecoder的输出以及目标序列，并预测目标序列中的下一个内容。\n",
    "\n",
    "如果你只处理一个单一的向量序列（或一组），你将只使用TransformerEncoder。\n",
    "\n",
    "下面是一个序列到序列的转化器，用于将源序列映射到目标序列（这个设置可以用于机器翻译或问题回答等）。\n",
    "\n",
    "```py\n",
    "encoder_inputs = keras.Input(shape=(sequence_length,), dtype=\"int64\")\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
    "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
    "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
    "x = TransformerDecoder(embed_dim, dense_dim, num_heads)(x, encoder_outputs)\n",
    "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
    "transformer = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "transformer.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这是一个单独的TransformerEncoder，用于整数序列的二进制分类。\n",
    "\n",
    "```py\n",
    "inputs = keras.Input(shape=(sequence_length,), dtype=\"int64\")\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(inputs)\n",
    "x = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TransformerEncoder、TransformerDecoder以及PositionalEmbedding层的完整实现将在第11章提供。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 可能性的空间\n",
    "\n",
    "你将用这些技术构建什么？记住，建立深度学习模型就像玩乐高积木一样：只要你有合适的训练数据，并且可以通过合理复杂的连续几何变换来实现映射，那么各层就可以插在一起，基本上可以映射到任何东西。可能性的空间是无限的。本节提供了一些例子，以启发你超越基本的分类和回归任务，这些任务在传统上一直是机器学习的面包和黄油。\n",
    "\n",
    "我把我建议的应用按输入和输出模式分类。请注意，其中相当多的应用扩展了可能的极限--尽管一个模型可以在所有这些任务上进行训练，但在某些情况下，这样的模型可能不会从其训练数据中概括出很多东西。第14.2、14.3和14.4节将讨论如何在未来解除这些限制。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将矢量数据映射到矢量数据\n",
    "\n",
    "    预测性医疗--将病人的医疗记录映射到对病人结果的预测上\n",
    "    行为定位--将一组网站属性与用户将在网站上花费多长时间的数据进行映射\n",
    "    产品质量控制--将一组相对于制造产品的实例的属性与该产品在明年发生故障的概率进行映射\n",
    "\n",
    "将图像数据映射为矢量数据\n",
    "\n",
    "    医疗助理--将医疗图像的幻灯片与预测肿瘤的存在进行映射\n",
    "    自动驾驶汽车--将汽车仪表盘视频帧映射到方向盘角度指令和油门及刹车指令上\n",
    "    棋盘游戏人工智能--将围棋或国际象棋棋盘映射到下一步棋。\n",
    "    饮食助手--将一道菜的图片映射到其卡路里数上\n",
    "    年龄预测--将自拍照映射到人的年龄上\n",
    "\n",
    "将时间序列数据映射为矢量数据\n",
    "\n",
    "    天气预测--将天气数据的时间序列映射到特定地点的下周天气数据的网格上\n",
    "    脑机接口--将脑磁图（MEG）数据的时间序列映射到计算机命令上\n",
    "    行为定位--将用户在网站上的互动时间序列映射到用户购买的概率上\n",
    "\n",
    "将文本映射到文本\n",
    "\n",
    "    机器翻译--将一种语言的段落映射到另一种语言的翻译版本上\n",
    "    智能回复--将电子邮件映射到可能的单行回复上\n",
    "    问题回答--将一般知识性的问题映射到答案上\n",
    "    总结--将一篇长文章映射为文章的简短摘要\n",
    "\n",
    "将图像映射到文本\n",
    "\n",
    "    文本转录--将包含文本元素的图像映射为相应的文本字符串\n",
    "    字幕--将图像映射为描述图像内容的简短字幕\n",
    "\n",
    "将文本映射到图像上\n",
    "\n",
    "    有条件的图像生成--将简短的文字描述映射到与该描述相匹配的图像上\n",
    "    标志生成/选择--将公司的名称和描述映射到标志建议上\n",
    "\n",
    "映射图像到图像\n",
    "\n",
    "    超分辨率--将缩小的图像映射到同一图像的高分辨率版本上\n",
    "    视觉深度感应--将室内环境的图像映射到深度预测的地图上\n",
    "\n",
    "将图像和文本映射到文本\n",
    "\n",
    "    视觉QA--将图像和关于图像内容的自然语言问题映射到自然语言答案上\n",
    "\n",
    "\n",
    "将视频和文本映射为文本\n",
    "\n",
    "    视频QA--将短视频和关于视频内容的自然语言问题映射到自然语言答案上\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "几乎任何事情都是可能的，但也不是完全可能。让我们在下一节看看我们不能用深度学习做什么。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 深度学习的局限性\n",
    "\n",
    "可以用深度学习实现的应用空间是无限的。然而，许多应用对于目前的深度学习技术来说仍然是完全无法企及的--即使给了大量的人类注释数据。比如说，你可以收集一个数据集，其中有几十万甚至几百万个由产品经理撰写的关于软件产品功能的英文描述，以及由工程师团队为满足这些要求而开发的相应源代码。即使有这些数据，你也无法训练一个深度学习模型来阅读产品描述并生成相应的代码库。这只是众多例子中的一个。一般来说，任何需要推理的东西，如编程或应用科学方法--长期规划，以及算法数据操作，对深度学习模型来说都是遥不可及的，无论你扔给它们多少数据。即使用深度神经网络学习一个简单的排序算法也是非常困难的。\n",
    "\n",
    "这是因为深度学习模型只是一个简单的、连续的几何变换链，将一个向量空间映射到另一个空间。它所能做的就是将一个数据流形X映射到另一个流形Y，假设存在一个从X到Y的可学习的连续变换。一个深度学习模型可以被解释为一种程序；但反过来说，大多数程序不能被表达为深度学习模型--对于大多数任务，要么不存在相应的合理规模的神经网络来解决这个任务，要么即使存在，它也可能是不可学习的：相应的几何变换可能太复杂，或者可能没有合适的数据来学习它。\n",
    "\n",
    "通过堆叠更多的层和使用更多的训练数据来扩大当前的深度学习技术，只能在表面上缓和其中的一些问题。它不会解决更根本的问题，即深度学习模型在它们所能代表的内容方面是有限的，而且你可能希望学习的大多数程序不能被表达为数据流形的连续几何变形。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将机器学习模型拟人化的风险\n",
    "\n",
    "当代人工智能的一个真正风险是误解了深度学习模型的作用，高估了它们的能力。人类的一个基本特征是我们的心智理论：我们倾向于将意图、信念和知识投射到我们周围的事物上。在一块石头上画一个笑脸，突然间让它变得 \"快乐\"--在我们的头脑中。应用于深度学习，这意味着，例如，当我们能够在某种程度上成功地训练一个模型来生成描述图片的标题时，我们就会相信这个模型 \"理解 \"图片的内容和它生成的标题。然后，当任何与训练数据中的图片类型稍有偏差，就会导致模型产生完全荒谬的标题时，我们会感到惊讶（见图14.1）。\n",
    "\n",
    "特别是，这一点在对抗性例子中得到了强调，对抗性例子是提供给深度学习网络的样本，旨在欺骗模型对其进行错误分类。你已经知道，例如，可以在输入空间中进行梯度上升，以产生最大限度地激活某些convnet过滤器的输入--这是第九章介绍的过滤器可视化技术的基础，也是第十二章的DeepDream算法。同样地，通过梯度上升，你可以稍微修改一张图片，以便最大限度地提高对某一特定类别的预测值。通过拍摄一张熊猫的照片并在其中加入长臂猿的梯度，我们可以让神经网络将熊猫分类为长臂猿（见图14.2）。这既证明了这些模型的脆性，也证明了它们的输入-输出映射与我们人类的感知之间存在着深刻的差异。\n",
    "\n",
    "简而言之，深度学习模型对它们的输入没有任何理解--至少，在人类的意义上没有。我们自己对图像、声音和语言的理解是建立在我们作为人类的感觉运动经验之上的。机器学习模型无法获得这些经验，因此无法以与人类相关的方式理解其输入。通过注释大量的训练实例以输入我们的模型，我们让它们学习一种几何变换，将数据映射到特定的实例集上的人类概念，但这种映射只是我们头脑中原始模型的一个简单的草图--一个从我们作为具身代理的经验中发展出来的模型。它就像镜子里的暗影（见图14.3）。你创建的模型会采取任何可用的捷径来适应他们的训练数据。例如，图像模型往往更依赖于局部纹理，而不是对输入图像的全局理解--在以豹子和沙发为特征的数据集上训练的模型很可能将豹子图案的沙发归为真正的豹子。\n",
    "\n",
    "作为一个机器学习的从业者，要时刻注意这一点，千万不要落入相信神经网络理解它们所执行的任务的陷阱中--它们不理解，至少对我们来说没有意义。它们被训练在一个不同的、比我们想教给它们的任务窄得多的任务上：即把训练输入与训练目标逐点映射。给他们看任何偏离其训练数据的东西，他们都会以荒谬的方式打破。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自动机与智能代理\n",
    "\n",
    "深度学习模型所做的从输入到输出的直接的几何变形，与人类的思考和学习方式之间存在着根本的区别。这不仅仅是人类自己从具体的经验中学习，而不是被赋予明确的训练实例的事实。与可分参数函数相比，人类的大脑是完全不同的野兽。\n",
    "\n",
    "让我们放大一点，问：智力的目的是什么？为什么它一开始就出现了？我们只能猜测，但我们可以做出相当有根据的猜测。我们可以从观察大脑开始--产生智力的器官。大脑是一种进化的适应性--一种在数亿年中通过自然选择指导下的随机试验和错误而逐步发展起来的机制--它极大地扩展了生物体适应环境的能力。大脑最初出现在5亿多年前，作为一种存储和执行行为程序的方式。\"行为程序 \"只是一组指令，使生物体对其环境作出反应。\"如果这个发生了，就做那个\"。它们将生物体的感觉输入与运动控制联系起来。在开始时，大脑将起到硬编码行为程序（作为神经连接模式）的作用，这将使生物体对其感觉输入作出适当的反应。这就是昆虫的大脑仍在工作的方式--苍蝇、蚂蚁、雅典娜（C. elegans）（见图14.4），等等。由于这些程序的原始 \"源代码 \"是DNA，它将被解码为神经连接模式，进化突然能够以一种基本无限制的方式搜索行为空间，这是一个重大的进化转变。\n",
    "\n",
    "进化是程序员，而大脑是仔细执行进化给它们的代码的计算机。由于神经连接是一个非常普遍的计算基质，所有具有大脑功能的物种的感觉运动空间可以突然开始经历一个巨大的扩展。眼睛、耳朵、下颚、四条腿、24条腿--只要你有一个大脑，进化就会好心地为你想出善用这些的行为程序。大脑可以处理任何模式或模式的组合--你扔给它们的模式。\n",
    "\n",
    "现在，请注意，这些早期的大脑本身并不完全智能。它们在很大程度上是自动装置：它们只是执行硬编码在生物体DNA中的行为程序。它们只能被描述为智能，就像恒温器是 \"智能 \"一样。或一个列表排序程序。或者......一个经过训练的深度神经网络（人工的那种）。这是一个重要的区别，所以让我们仔细看看：自动装置和实际的智能代理之间有什么区别？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 局部泛化与极端泛化\n",
    "\n",
    "17世纪的法国哲学家和科学家René Descartes在1637年写了一篇富有启发性的评论，完美地抓住了这种区别--早于人工智能的兴起，事实上，早于第一台机械计算机（他的同事Pascal将在五年后创造）。笛卡尔在提到自动装置时告诉我们。\n",
    "\n",
    "即使这样的机器在某些方面可能做得和我们一样好，甚至更好，但它们在其他方面将不可避免地失败，这将表明它们不是通过理解而行动的，而只是根据其器官的处置。\n",
    "\n",
    "这就是了。智能的特点是理解，而理解的证据是概括--处理可能出现的任何新情况的能力。你如何区分一个背诵了过去三年的考试题但对该学科毫无了解的学生和一个真正了解该材料的学生呢？你给他们一个全新的问题。自动机是静态的，在特定的环境下完成特定的事情--\"如果这样，那么那样\"--而智能代理可以在飞行中适应新的、意外的情况。当自动机被暴露在不符合其 \"编程 \"的东西面前时（无论我们谈论的是人类编写的程序、进化产生的程序，还是在训练数据集上拟合模型的隐性编程过程），它将失败。同时，智能代理，像我们人类一样，将利用他们的理解力来找到前进的道路。\n",
    "\n",
    "人类的能力远远超过将即时刺激映射到即时反应，就像深度网络或昆虫那样。我们对自己的现状、对自己、对其他人都保持着复杂、抽象的模型，并能利用这些模型来预测不同的可能的未来，进行长期规划。你可以把已知的概念融合在一起，以表示你以前从未经历过的事情--比如想象一下如果你中了彩票你会怎么做，或者想象一下如果你悄悄地把她的钥匙换成弹性橡胶制成的精确拷贝，你的朋友会有什么反应。这种处理新奇事物和 \"如果 \"的能力，将我们的心理模型空间扩大到远远超过我们可以直接体验到的东西--利用抽象和推理，是人类认知的决定性特征。我把它称为极端概括：一种适应新的、从未经历过的情况的能力，使用很少的数据，甚至根本没有新数据。这种能力是人类和高级动物所展示的智能的关键。\n",
    "\n",
    "这与类似自动机的系统所做的事情形成了鲜明的对比。一个非常僵化的自动机根本就没有任何概括性的特征--它将无法处理任何事先没有被精确告知的事情。Python的dict，或者以硬编码的if-then-else语句实现的基本问题回答程序就属于这一类。深度网做得稍微好一点：它们可以成功地处理与它们所熟悉的内容有一些偏差的输入--这正是使它们有用的地方。我们在第8章中的猫狗模型可以对它以前没有见过的猫或狗的图片进行分类，只要它们与它所训练的内容足够接近。然而，深度网络仅限于我所说的局部泛化（见图14.5）：当输入开始偏离网络在训练时看到的内容时，深度网络执行的从输入到输出的映射很快就失去意义。深度网只能对已知的未知因素进行泛化，即在模型开发过程中预计到的、在训练数据中广泛存在的变化因素，例如宠物照片的不同摄影角度或照明条件。这是因为深度网是通过流形上的插值进行泛化的（记得第五章）：输入空间中的任何变化因素都需要被他们学习的流形所捕获。这就是为什么基本的数据增强对改善深度网的泛化有很大帮助。与人类不同，这些模型没有能力在很少或没有数据的情况下随机应变（比如中彩票或被递给橡皮钥匙），这些情况只与过去的情况有抽象的共同点。\n",
    "\n",
    "\n",
    "例如，考虑学习适当的发射参数以使火箭降落在月球上的问题。如果您使用深度网络完成这项任务并使用监督学习或强化学习对其进行训练，则您必须为其提供数万次甚至数百万次启动试验：您需要将其暴露于输入的密集采样空间，以便它学习从输入空间到输出空间的可靠映射。相比之下，作为人类，我们可以利用我们的抽象能力来提出物理模型——火箭科学——并推导出一个精确的解决方案，在一次或几次试验中将火箭降落在月球上。类似地，如果你开发了一个控制人体的深度网络，并且你想让它学会在不被汽车撞到的情况下安全地在城市中穿行，那么网络将不得不在各种情况下死亡数千次，直到它可以推断出汽车是危险，并制定适当的回避行为。进入一个新城市，网络将不得不重新学习它所知道的大部分内容。另一方面，人类能够学习安全的行为而不必死一次——再次感谢我们对新情况的抽象建模能力。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 情报的目的\n",
    "\n",
    "高度适应性智能代理和刚性自动机之间的这种区别将我们带回了大脑进化。为什么大脑——最初只是自然进化发展行为自动机的媒介——最终变得智能？就像每一个重要的进化里程碑一样，它的发生是因为自然选择的限制促使它发生。\n",
    "\n",
    "大脑负责行为的产生。如果有机体必须面对的情况大多是静态的并且是预先知道的，那么行为生成将是一个简单的问题：进化将通过随机试错找出正确的行为，并将它们硬编码到有机体的 DNA 中。大脑进化的第一阶段——大脑作为自动机——已经是最佳的。然而，至关重要的是，随着生物体的复杂性——以及随之而来的环境复杂性——不断增加，动物必须应对的情况变得更加动态和不可预测。如果你仔细观察，你生命中的一天不同于你经历过的任何一天，也不同于你的任何进化祖先经历过的任何一天。您需要能够不断面对未知和令人惊讶的情况。进化无法找到并将您作为 DNA 硬编码的行为序列，以便您从几个小时前醒来后成功地度过一天。它必须每天动态生成。\n",
    "\n",
    "大脑，作为一个很好的行为生成引擎，只是适应了这种需求。它针对适应性和通用性本身进行了优化，而不仅仅是针对一组固定情况进行优化。这种转变可能在整个进化史上发生过多次，导致在非常遥远的进化分支——猿、章鱼、乌鸦等——中产生了高度智能的动物。智能是应对复杂、动态生态系统所带来挑战的答案。\n",
    "\n",
    "这就是智能的本质：它能够有效地利用您所掌握的信息，以便在面对不确定、不断变化的未来时产生成功的行为。笛卡尔所说的“理解”是这种非凡能力的关键：挖掘您过去的经验以开发模块化、可重用的抽象的能力，这些抽象可以快速重新用于处理新情况，并实现极端泛化。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 泛化的范围\n",
    "\n",
    "作为粗略的漫画，您可以将生物智能的进化历史概括为泛化范围的缓慢攀升。它始于只能执行局部泛化的类似自动机的大脑。随着时间的推移，进化开始产生能够进行更广泛泛化的生物体，它们可以在越来越复杂和多变的环境中茁壮成长。最终，在过去的几百万年里——从进化的角度来说是一瞬间——某些人类物种开始趋向于实现能够极端概括的生物智能，促使人类世的开始并永远改变地球上生命的历史。\n",
    "\n",
    "人工智能在过去 70 年的进步与这种演变有着惊人的相似之处。早期的人工智能系统是纯自动机，比如 1960 年代的 ELIZA 聊天程序，或 SHRDLU：[40]，这是 1970 年的人工智能，能够通过自然语言命令操作简单的对象。在 1990 年代和 2000 年代，我们看到了能够进行局部泛化的机器学习系统的兴起，它可以处理一定程度的不确定性和新颖性。在 2010 年代，深度学习使工程师能够利用更大的数据集和更具表现力的模型，进一步扩展了这些系统的局部泛化能力。\n",
    "\n",
    "今天，我们可能正处于下一个进化步骤的风口浪尖上。人们对能够实现广泛泛化的系统越来越感兴趣，我将其定义为在单一广泛的任务领域内处理未知未知数的能力（包括系统未经训练处理的情况及其创建者无法预料的情况）。例如，一辆能够安全处理任何情况的自动驾驶汽车，或者一个可以通过“Woz 智力测试”的家用机器人——随机进入厨房并煮一杯咖啡：[41]。通过将深度学习和精心制作的世界抽象模型相结合，我们已经在朝着这些目标取得明显进展。\n",
    "\n",
    "然而，目前，人工智能仍然仅限于认知自动化：“人工智能”中的“智能”标签是一个类别错误。将我们的领域称为“人工智能”会更准确，“认知自动化”和“人工智能”是其中两个几乎独立的子领域。在这个细分领域，“人工智能”将是一片绿地，几乎所有东西都有待发现。\n",
    "\n",
    "现在，我并不是要贬低深度学习的成就。认知自动化非常有用，深度学习模型能够将任务从暴露到数据中自动化的方式代表了认知自动化的一个特别强大的方法，比显式编程更实用和通用。做好这件事基本上可以改变每个行业的游戏规则。但这离人类（或动物）智能还有很长的路要走。到目前为止，我们的模型只能执行局部泛化：它们通过从 X 到 Y 数据点的密集采样中学习到的平滑几何变换将空间 X 映射到空间 Y，并且空间 X 或 Y 内的任何中断都会使该映射无效。它们只能泛化到与过去数据保持相似的新情况——而人类认知能够极端泛化，快速适应全新的情况并为未来的长期情况做规划。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 通用AI\n",
    "\n",
    "为了消除我们讨论过的一些限制并创建可以与人脑竞争的人工智能，我们需要从简单的输入到输出映射转向推理和抽象。在接下来的几节中，我们将看看未来的道路可能是什么样子。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 关于设定正确目标的重要性：捷径\n",
    "\n",
    "生物智能是对大自然提出的问题的回答。同样，如果我们想开发真正的人工智能，首先，我们需要提出正确的问题。\n",
    "\n",
    "您在系统设计中经常看到的一个效果是捷径规则：如果您专注于优化一个成功指标，您将实现目标，但代价是系统中未包含在您的成功指标中的所有内容。您最终会采取所有可用的捷径来实现目标。你的创作是由你给自己的激励塑造的。\n",
    "\n",
    "您经常在机器学习竞赛中看到这一点。 2009 年，Netflix 发起了一项挑战，承诺向在电影推荐任务中获得最高分的团队提供 100 万美元的奖金。它最终从未使用获胜团队创建的系统，因为它太复杂且计算密集型。获胜者仅针对预测准确性进行了优化——他们被激励实现的目标——以牺牲系统的所有其他理想特性为代价：推理成本、可维护性、可解释性。捷径规则在大多数 Kaggle 比赛中也适用——Kaggle 获胜者制作的模型很少（如果有的话）用于生产。\n",
    "\n",
    "在过去的几十年里，捷径规则在人工智能中无处不在。在 1970 年代，心理学家和计算机科学先驱艾伦纽厄尔担心他的领域在正确的认知理论方面没有取得任何有意义的进展，为人工智能提出了一个新的宏伟目标：下棋。其基本原理是，人类下棋似乎涉及——甚至可能需要——诸如感知、推理和分析、记忆和书本学习等能力。当然，如果我们能建造一个国际象棋机器，它也必须具有这些属性。对？\n",
    "\n",
    "24 年后，梦想成真：1997 年，IBM 的 DeepBlue 击败了世界上最好的国际象棋选手 Gary Kasparov。然后，研究人员不得不面对这样一个事实，即创建国际象棋冠军 AI 并没有教会他们关于人类智能的知识。 DeepBlue 核心的 A-star 算法不是人脑模型，不能推广到类似棋盘游戏以外的任务。事实证明，建立一个只会下棋的人工智能比建立一个人工大脑更容易——所以这就是研究人员采取的捷径。\n",
    "\n",
    "迄今为止，AI 领域的驱动成功指标一直是解决特定任务，从国际象棋到围棋，从 MNIST 分类到 ImageNet，从 Atari Arcade 游戏到星际争霸和 DotA 2。因此，该领域的历史已经被定义通过一系列“成功”，我们找到了如何在没有任何智能的情况下解决这些任务。\n",
    "\n",
    "如果这听起来令人惊讶的话，请记住，类人智能的特征不在于任何特定任务的技能——而是适应新事物、有效获取新技能和掌握前所未见的能力任务。通过修复任务，您可以对需要完成的工作提供任意精确的描述——通过硬编码人类提供的知识，或通过提供大量数据。工程师只需添加数据或添加硬编码知识，就可以为他们的 AI“购买”更多技能，而无需增加 AI 的泛化能力（见图 14.6）。如果你有近乎无限的训练数据，即使是像最近邻搜索这样非常粗糙的算法也能以超人的技能玩电子游戏。同样，如果您有几乎无限量的人工编写的 if-then-else 语句。那就是……直到你对游戏规则做一个小的改变——人类可以立即适应的那种——这将需要重新训练或从头开始重建非智能系统。\n",
    "\n",
    "简而言之，通过固定任务，您就不需要处理不确定性和新颖性，而且由于智能的本质是处理不确定性和新颖性的能力，因此您可以有效地消除对智能的需求。 并且因为为特定任务找到非智能解决方案总是比解决一般的智能问题更容易，所以这是你 100% 时间都会走的捷径。 人类可以利用他们的通用智能来获得任何新任务的技能，但反过来，从特定任务的技能集合到通用智能是没有途径的。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 新目标\n",
    "\n",
    "为了使人工智能真正具有智能，并赋予其处理现实世界令人难以置信的可变性和不断变化的性质的能力，首先，我们需要摆脱寻求实现特定任务的技能，而是开始瞄准泛化权力本身。我们需要新的进展指标来帮助我们开发越来越智能的系统。指标将指向正确的方向，并为我们提供可操作的反馈信号。只要我们将目标设定为“创建一个解决任务 X 的模型”，捷径规则就会适用，我们最终会得到一个执行 X 任务的模型。\n",
    "\n",
    "在我看来，智能可以精确地量化为一个效率比：你所掌握的有关世界的相关信息量（可以是过去的经验，也可以是先天的先验知识）与你未来的操作领域之间的转化率，即集合您将能够产生适当行为的新情况（您可以将其视为您的技能）。一个更智能的代理将能够使用更少的过去经验来处理更广泛的未来任务和情况。要测量这样的比率，您只需要确定系统可用的信息——它的经验和它的先验知识——并测量它在一组已知与系统已有的完全不同的参考情况或任务上的性能进入。试图最大化这个比率应该会引导你走向智慧。至关重要的是，为了避免作弊，您将需要确保仅在未经过编程或培训处理的任务上测试系统——事实上，您需要系统创建者无法预料的任务。\n",
    "\n",
    "在 2018 年和 2019 年，我开发了一个名为抽象与推理语料库（ARC）的基准数据集：[42] 旨在捕捉智能的这种定义。 ARC 旨在让机器和人类都可以使用，它看起来与人类 IQ 测试非常相似，例如 Raven 的渐进矩阵。在测试时，您会看到一系列“任务”。每个任务都通过三个或四个“示例”来解释，这些“示例”采用输入网格和相应的输出网格的形式（见图 14.7）。然后，您将获得一个全新的输入网格，在继续下一个任务之前，您将有 3 次尝试生成正确的输出网格。\n",
    "\n",
    "与 IQ 测试相比，ARC 有两个独特之处。首先，ARC 旨在衡量泛化能力，只在您以前从未见过的任务上测试您。这意味着 ARC 是一款您无法练习的游戏，至少在理论上是这样：您将接受测试的任务将具有自己独特的逻辑，您必须即时理解这些逻辑。您不能只记住过去任务中的特定策略。\n",
    "\n",
    "此外，ARC 尝试控制您带入测试的先验知识。你永远不会完全从头开始解决一个新问题——你会带来预先存在的技能和信息。 ARC 假设所有应试者都应该从一组知识先验开始，称为“核心知识先验”，代表人类与生俱来的“知识系统”。与智商测试不同，ARC 任务永远不会涉及获得的知识，例如英语句子。\n",
    "\n",
    "不出所料，基于深度学习的方法（包括在大量外部数据上训练的模型，如 GPT-3）已被证明完全无法解决 ARC 任务，因为这些任务是非插值的，因此不太适合曲线 -配件。同时，普通人在没有任何练习的情况下第一次尝试解决这些任务是没有问题的。当你看到这样的情况时，年仅 5 岁的人类就能够自然地执行现代人工智能技术似乎完全无法实现的事情，这清楚地表明它正在发生一些有趣的事情——我们错过了一些东西.\n",
    "\n",
    "解决ARC需要什么？希望这个挑战能让你思考。这就是 ARC 的全部意义所在：给你一个不同类型的目标，这将推动你走向一个新的方向——希望是一个富有成效的方向。现在，让我们快速浏览一下如果您想接听电话，您将需要的关键要素。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 智能缺少的部分\n",
    "\n",
    "到目前为止，您已经了解到，除了深度学习所做的那种潜在的流形插值之外，智能还有很多东西。但是，那么，我们需要什么才能开始构建真正的智能呢？目前我们无法掌握的核心部分是什么？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 智力对抽象类比的敏感性\n",
    "\n",
    "智力是利用你过去的经验（和先天的先验知识）来面对新的、意想不到的未来情况的能力。现在，如果你不得不面对的未来真的是新奇的——与你以前见过的任何事物都没有共同点——你将无法对它做出反应，无论你多么聪明。\n",
    "\n",
    "情报之所以有效，是因为没有什么是真正没有先例的。当我们遇到新事物时，我们能够通过与过去的经验进行类比，根据我们随着时间的推移收集到的抽象概念来阐明它，从而理解它。一个 17 世纪第一次看到喷气式飞机的人可能会把它描述为一只大而响亮的金属鸟，它不会扇动翅膀。一辆车？那是一辆无马车。如果您正在尝试向小学生教授物理，您可以解释电如何像管道中的水，或者时空如何像橡胶板被重物扭曲。\n",
    "\n",
    "除了这种清晰、明确的类比之外，我们还在不断地进行更小、更隐含的类比——每一秒，每一个想法。类比是我们驾驭生活的方式。去新的超市？您将通过将其与您去过的类似商店相关联来找到自己的方式。与新人交谈？他们会让你想起你以前见过的一些人。即使看似随机的图案，如云的形状，也会立即在我们心中唤起生动的形象——大象、船、鱼。\n",
    "\n",
    "这些类比也不仅仅存在于我们的脑海中：物理现实本身就充满了同构。电磁学类似于重力。由于共同的起源，动物在结构上彼此相似。二氧化硅晶体类似于冰晶。等等。\n",
    "\n",
    "我称之为万花筒假设：我们对世界的体验似乎具有难以置信的复杂性和永无止境的新奇，但在这片复杂的海洋中，一切都与其他一切相似。描述你所生活的宇宙所需的具有意义的独特原子的数量相对较少，而你周围的一切都是这些原子的重组。几粒种子，变化无穷。就像万花筒内部发生的事情一样，几个玻璃珠被镜子系统反射，产生丰富的、看似无穷无尽的图案（见图 14.8）。 \n",
    "\n",
    "泛化能力——智能——是挖掘你的经验以识别这些似乎可以在许多不同情况下重复使用的意义原子的能力。一旦提取出来，它们就被称为抽象。每当您遇到新情况时，您都会通过积累的抽象集合来理解它。你如何识别可重复使用的意义原子？只需注意两件事何时相似——注意类比。如果某事重复两次，则两个实例都必须有一个来源。就像在万花筒里一样。抽象是智力的引擎，类比是产生抽象的引擎。\n",
    "\n",
    "简而言之，智力实际上是对抽象类比的敏感性，而这实际上就是它的全部。如果你对类比有很高的敏感性，你就会从很少的经验中提取出强大的抽象，并且你将能够使用这些抽象在未来经验空间的最大区域中进行操作。您将最有效地将过去的经验转化为应对未来新奇事物的能力。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 抽象的两个极点\n",
    "\n",
    "如果智能对类比很敏感，那么开发人工智能应该从拼出一个用于类比的分步算法开始。类比从将事物相互比较开始。至关重要的是，有两种不同的比较事物的方法，从中产生了两种不同的抽象，两种思维模式，每种都更适合不同类型的问题。这两个抽象极点共同构成了我们所有思想的基础。\n",
    "\n",
    "将事物相互关联的第一种方法是相似性比较，这产生了以价值为中心的类比。第二种方式是精确结构匹配，它产生了以程序为中心的类比（或以结构为中心的类比）。在这两种情况下，您都从事物的实例开始，然后将相关实例合并在一起以产生一个抽象，该抽象捕获底层实例的公共元素。不同的是你如何判断两个实例是相关的，以及你如何将实例合并为抽象。让我们仔细看看每种类型。\n",
    "以价值为中心的类比\n",
    "\n",
    "假设您在后院遇到了许多不同的甲虫，它们属于多个物种。你会注意到它们之间的相似之处。有些会更相似，有些会不太相似：相似性的概念隐含地是一个平滑的、连续的距离函数，它定义了你的实例所在的潜在流形。一旦您看到足够多的甲虫，您就可以开始将更多相似的实例聚集在一起，并将它们合并为一组原型，以捕捉每个集群的共享视觉特征。这个原型是抽象的：它看起来不像你见过的任何特定实例，尽管它编码了所有这些共同的属性。当您遇到一种新甲虫时，您无需将它与以前见过的每只甲虫进行比较，就可以知道如何处理它。你可以简单地将它与你的少数原型进行比较，从而找到最接近的原型——甲虫的类别——并用它来做出有用的预测：甲虫可能会咬你吗？它会吃你的苹果吗？ \n",
    "\n",
    "这听起来很熟悉吗？它几乎是对无监督机器学习（例如 K-means 聚类算法）的作用的描述。一般来说，所有现代机器学习，无论是否无监督，都是通过学习描述实例空间的潜在流形来工作的，通过原型编码（还记得你在第 9 章中可视化的 convnet 特征吗？它们是视觉原型）。以价值为中心的类比是一种使深度学习模型能够进行局部泛化的类比。\n",
    "\n",
    "这也是您自己的许多认知能力所依赖的。作为人类，您一直在进行以价值为中心的类比。这种抽象类型是模式识别、感知和直觉的基础。如果您可以不假思索地完成一项任务，那么您就严重依赖以价值为中心的类比。如果你正在看电影并且开始下意识地将不同的角色归类为“类型”，这就是以价值为中心的抽象。\n",
    "以程序为中心的类比\n",
    "\n",
    "至关重要的是，认知不仅仅是以价值为中心的类比所实现的那种直接、近似、直观的分类。还有另一种抽象生成机制，更慢、更精确、深思熟虑：以程序为中心（或以结构为中心）的类比。\n",
    "\n",
    "在软件工程中，您经常编写看起来有很多共同点的不同函数或类。当你注意到这些冗余时，你开始问：是否有一个更抽象的函数来执行相同的工作，可以重复使用两次？我的两个类都可以继承一个抽象基类吗？您在这里使用的抽象定义对应于以程序为中心的类比。你不是试图通过它们看起来有多相似来比较你的类和函数，就像你通过隐式距离函数比较两张人脸的方式。相反，您感兴趣的是它们的某些部分是否具有完全相同的结构。您正在寻找所谓的子图同构（见图 14.10）：程序可以表示为运算符图，并且您正在尝试找到在不同程序之间完全共享的子图（程序子集）。\n",
    "\n",
    "这种通过不同离散结构内的精确结构匹配进行类比的类比完全不是计算机科学或数学等专业领域所独有的——你在不知不觉中不断地使用它。 它是推理、计划和严格的一般概念（与直觉相对）的基础。 每当您考虑通过离散的关系网络（而不是连续的相似性函数）相互连接的对象时，您就是在利用以程序为中心的类比。\n",
    "认知是两种抽象的结合\n",
    "\n",
    "让我们并排比较这两个抽象极点： "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "表 14.1。 抽象的两个极点。\n",
    "以值为中心的抽象 以程序为中心的抽象\n",
    "\n",
    "通过距离来关联事物。\n",
    "\n",
    "\n",
    "通过精确的结构匹配来关联事物。\n",
    "\n",
    "连续的，以几何学为基础。\n",
    "\n",
    "\n",
    "离散的，以拓扑为基础。\n",
    "\n",
    "通过将实例“平均”为“原型”来产生抽象。\n",
    "\n",
    "\n",
    "通过跨实例隔离同构子结构来产生抽象。\n",
    "\n",
    "感知和直觉的基础。\n",
    "\n",
    "\n",
    "推理和计划的基础。\n",
    "\n",
    "直接、模糊、近似。\n",
    "\n",
    "\n",
    "缓慢、准确、严谨。\n",
    "\n",
    "需要大量的经验才能产生可靠的结果。\n",
    "\n",
    "\n",
    "体验效率高，可以操作最少两个实例。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们所做的一切，我们所想的一切，都是这两种抽象类型的结合。 你很难找到只涉及两者之一的任务。 即使是一个看似“纯感知”的任务，比如识别场景中的物体，也涉及大量关于你正在看的物体之间关系的隐性推理。 甚至一个看似“纯推理”的任务，比如找到数学定理的证明，也涉及大量的直觉。 当数学家把笔放在纸上时，他们已经对前进的方向有了模糊的认识。 他们到达目的地所采取的离散推理步骤是由高级直觉指导的。\n",
    "\n",
    "这两个极点是互补的，正是它们的交错使极端泛化成为可能。 没有这两者，任何心灵都不可能完整。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 缺失的另一半\n",
    "\n",
    "至此，您应该开始看到现代深度学习缺少什么：它非常擅长编码以价值为中心的抽象，但它基本上没有能力生成以程序为中心的抽象。类人智能是两种类型的紧密交织，所以我们实际上缺少了我们需要的一半——可以说是最重要的一半。\n",
    "\n",
    "现在，这里有一个警告。到目前为止，我已经将每种类型的抽象呈现为彼此完全分开的——甚至是相反的。然而，在实践中，它们更像是一个频谱：在某种程度上，您可以通过将离散程序嵌入到连续流形中来进行推理——就像您可以通过任何一组离散点拟合多项式函数一样，只要您有足够的系数。相反，您可以使用离散程序来模拟连续距离函数——毕竟，当您在计算机上进行线性代数时，您已经在处理连续空间，完全是通过对 1 和 0 进行运算的离散程序。\n",
    "\n",
    "但是，显然有一些类型的问题更适合其中一个。例如，尝试训练一个深度学习模型来对包含五个数字的列表进行排序。使用正确的架构，这并非不可能，但它是一种挫折练习。你需要大量的训练数据来实现它——即便如此，模型在呈现新数字时仍然会偶尔出错。如果您想开始对 10 个数字的列表进行排序，则需要完全重新训练模型——甚至更多的数据。同时，用 Python 编写排序算法只需要几行代码——而且生成的程序，一旦在更多的例子上得到验证，每次都能在任何大小的列表上运行。这是非常强的概括：从几个演示示例和测试示例到可以成功处理几乎任何数字列表的程序。\n",
    "\n",
    "相反，感知问题非常适合离散推理过程。尝试编写一个纯 Python 程序来对 MNIST 数字进行分类，而不使用任何机器学习技术：您是在兜风。您会发现自己在苦心编写可以检测数字中闭环数量、数字质心坐标等的函数。经过数千行代码，您可能会达到…… 90% 的测试准确率。在这种情况下，拟合参数模型要简单得多，它可以更好地利用大量可用数据，并获得更稳健的结果。如果您有大量数据，并且面临应用流形假设的问题，请使用深度学习。\n",
    "\n",
    "出于这个原因，我们不太可能看到一种将推理问题减少到流形插值或将感知问题减少到离散推理的方法的兴起。人工智能的前进方向是开发一个统一的框架，将两种类型的抽象类比结合起来。让我们来看看它可能是什么样子。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The future of deep learning\n",
    "\n",
    "鉴于我们对深度网络的工作原理、局限性以及目前缺少的内容的了解，我们能否预测中期情况的发展方向？以下纯属个人想法。请注意，我没有水晶球，所以我预期的很多东西可能无法成为现实。我分享这些预测并不是因为我希望它们在未来被证明是完全正确的，而是因为它们在当下很有趣且可操作。\n",
    "\n",
    "在高层次上，这些是我认为有希望的主要方向：\n",
    "\n",
    "    更接近通用计算机程序的模型，建立在比当前可微层更丰富的原语之上。这就是我们将如何进行推理和抽象，缺乏推理和抽象是当前模型的根本弱点。\n",
    "    深度学习与程序空间离散搜索的融合，前者提供感知和直觉能力，后者提供推理和规划能力。\n",
    "    对先前学习的功能和架构进行更大程度的系统重用，例如使用可重用和模块化程序子例程的元学习系统。\n",
    "\n",
    "此外，请注意，这些考虑因素并不特定于迄今为止作为深度学习基础的监督学习——而是适用于任何形式的机器学习，包括无监督、自监督和强化学习。你的标签来自哪里或你的训练循环是什么样子并不重要；机器学习的这些不同分支是同一结构的不同方面。让我们深入了解。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型作为程序\n",
    "\n",
    "正如前一节所指出的，我们在机器学习领域可以期待的一个必要的转型发展是从纯粹执行模式识别并且只能实现局部泛化的模型转向能够实现极端抽象和推理的模型。概括。当前能够进行基本推理的 AI 程序都是由人类程序员硬编码的：例如，依赖于搜索算法、图形操作和形式逻辑的软件。\n",
    "\n",
    "由于程序合成，这可能即将改变——今天这个领域非常小众，但我希望在未来几十年里大放异彩。程序合成包括使用搜索算法（可能是遗传搜索，如遗传编程）自动生成简单的程序，以探索大量可能的程序（见图 14.11）。当找到与所需规范相匹配的程序时，搜索停止，通常以一组输入-输出对的形式提供。这很容易让人联想到机器学习：给定作为输入-输出对提供的训练数据，我们找到了一个将输入与输出匹配并可以推广到新输入的程序。不同之处在于，我们不是在硬编码程序（神经网络）中学习参数值，而是通过离散搜索过程生成源代码（见表 14.2）。\n",
    "\n",
    "程序综合是我们将如何向我们的 AI 系统添加以程序为中心的抽象功能。这是拼图的缺失部分。我之前提到过，深度学习技术在 ARC（一种以推理为重点的智力测试）上完全无法使用。同时，非常粗略的程序综合方法已经在这个基准上产生了非常有希望的结果。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 深度学习和程序合成的结合\n",
    "\n",
    "当然，深度学习不会去任何地方。程序综合不是它的替代品，而是它的补充。迄今为止，我们的人工大脑还缺少这个半球。我们将结合利用两者。这将有两种主要方式：\n",
    "\n",
    "    开发集成深度学习模块和离散算法模块的系统。\n",
    "    使用深度学习使程序搜索过程本身更加高效。\n",
    "\n",
    "让我们回顾一下这些可能的途径。\n",
    "将深度学习模块和算法模块集成到混合系统中\n",
    "\n",
    "今天，最强大的人工智能系统是混合的：它们利用深度学习模型和手工制作的符号操作程序。例如，在 DeepMind 的 AlphaGo 中，显示的大部分智能都是由人类程序员设计和硬编码的（例如蒙特卡罗树搜索）。从数据中学习只发生在专门的子模块（价值网络和政策网络）中。或者考虑自动驾驶汽车：自动驾驶汽车能够处理各种各样的情况，因为它维护着一个周围世界的模型——一个字面的 3D 模型——充满了人类工程师硬编码的假设。该模型通过深度学习感知模块不断更新，这些模块将其与汽车周围环境相连接。\n",
    "\n",
    "对于这两个系统——AlphaGo 和自动驾驶汽车——人类创建的离散程序和学习到的连续模型的结合释放了单独使用任何一种方法都无法实现的性能水平，例如端到端深度网络，或一款没有 ML 元素的软件。到目前为止，这种混合系统的离散算法元素是由人类工程师煞费苦心地硬编码的。但在未来，此类系统可能会被完全学习，无需人工参与。\n",
    "\n",
    "这会是什么样子？考虑一种众所周知的网络类型：RNN。需要注意的是，RNN 的限制比前馈网络要少一些。这是因为 RNN 不仅仅是几何变换：它们是在 for 循环中重复应用的几何变换。时间 for 循环本身是由人类开发人员硬编码的：它是网络的内置假设。自然地，RNN 可以表示的内容仍然极其有限，主要是因为它们执行的每一步都是可微的几何变换，并且它们通过连续几何空间中的点（状态向量）逐步携带信息。现在想象一个神经网络，它通过编程原语以类似的方式增强——但不是一个带有硬编码连续空间内存的硬编码 for 循环，网络包含大量编程原语，模型可以自由操纵这些原语以扩展其处理能力函数，例如 if 分支、while 语句、变量创建、长期内存的磁盘存储、排序运算符、高级数据结构（例如列表、图形和哈希表）等等。这种网络可以表示的程序空间将比当前的深度学习模型可以表示的范围广得多，其中一些程序可以实现卓越的泛化能力。重要的是，这样的程序不会是端到端的——尽管特定的模块将保持可微——因此需要通过离散程序搜索和梯度下降的组合来生成。\n",
    "\n",
    "一方面，我们将不再拥有硬编码的算法智能（手工软件），另一方面，我们将不再拥有学习的几何智能（深度学习）。相反，我们将混合提供推理和抽象能力的正式算法模块，以及提供非正式直觉和模式识别能力的几何模块。整个系统将在很少或没有人工参与的情况下学习。这应该会极大地扩大机器学习可以解决的问题的范围——我们可以在给定适当的训练数据的情况下自动生成程序的空间。像 AlphaGo 甚至 RNN 这样的系统可以被视为这种混合算法-几何模型的史前祖先。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用深度学习指导程序搜索\n",
    "\n",
    "今天，程序综合面临着一个主要障碍：效率极低。讽刺的是，程序综合的工作原理是在搜索空间中尝试每个可能的程序，直到找到与所提供的规范相匹配的程序。随着程序规范的复杂性增加，或者随着用于编写程序的原语词汇量的扩大，程序搜索过程会遇到所谓的组合爆炸：要考虑的可能程序集增长得非常快，事实上，比只是指数级的快。结果，今天，程序合成只能用于生成非常短的程序。您不会很快为您的计算机生成新的操作系统。\n",
    "\n",
    "为了向前迈进，我们需要通过让程序合成更接近人类编写软件的方式来提高程序合成的效率。当您打开编辑器编写脚本时，您并没有考虑可能编写的每个可能的程序。你脑子里只有少数几种可能的方法：你可以利用你对问题的理解和过去的经验来彻底削减可能的选择空间。\n",
    "\n",
    "深度学习可以帮助程序合成做同样的事情：虽然我们想要生成的每个特定程序可能是一个执行非插值数据操作的基本离散对象，但迄今为止的证据表明，所有有用程序的空间可能看起来很像连续流形。这意味着，经过数百万个成功的程序生成片段训练的深度学习模型可能会开始对搜索过程从规范到相应程序的程序空间路径产生可靠的直觉。就像软件工程师可能对他们将要编写的脚本的整体架构有直接的直觉，他们应该使用中间函数和类作为实现目标的垫脚石。\n",
    "\n",
    "请记住，人类推理很大程度上受以价值为中心的抽象的指导，也就是说，受模式识别和直觉的指导。程序综合也应如此。我预计在未来 10 到 20 年内，通过学习启发式指导程序搜索的一般方法会引起越来越多的研究兴趣。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 终身学习和模块化子程序重用\n",
    "\n",
    "如果模型变得更复杂并且建立在更丰富的算法原语之上，那么这种增加的复杂性将需要在任务之间进行更高的重用，而不是每次我们有新任务或新数据集时从头开始训练新模型。许多数据集没有包含足够的信息让我们从头开始开发一个新的、复杂的模型，并且有必要使用以前遇到的数据集的信息（就像你每次打开一本新书时都没有从头开始学习英语一样） ——那是不可能的）。由于当前任务与之前遇到的任务之间存在很大的重叠，因此在每个新任务上从头开始训练模型也效率低下。\n",
    "\n",
    "近年来，人们反复进行了一项非凡的观察：训练同一个模型同时执行多个松散连接的任务会导致模型在每个任务上都表现得更好。例如，训练相同的神经机器翻译模型来执行英语到德语的翻译和法语到意大利语的翻译将产生一个在每个语言对上都更好的模型。类似地，将图像分类模型与图像分割模型联合训练，共享相同的卷积基础，会导致模型在这两个任务上都表现更好。这是相当直观的：看似断开连接的任务之间总是存在一些信息重叠，并且联合模型可以访问关于每个单独任务的更多信息，而不是仅在该特定任务上训练的模型。\n",
    "\n",
    "目前，当涉及跨任务的模型重用时，我们对执行常见功能（例如视觉特征提取）的模型使用预训练权重。你在第 9 章中看到了这一点。在未来，我希望它的通用版本是司空见惯的：我们不仅会使用以前学习的特征（子模型权重），还会使用模型架构和训练程序。随着模型变得更像程序，我们将开始重用程序子程序，如人类编程语言中的函数和类。\n",
    "\n",
    "想想今天的软件开发过程：一旦工程师解决了一个特定的问题（例如 Python 中的 HTTP 查询），他们就会将其打包为一个抽象的、可重用的库。将来遇到类似问题的工程师将能够搜索现有库，下载一个，并在他们自己的项目中使用它。以类似的方式，未来，元学习系统将能够通过筛选高级可重用块的全局库来组装新程序。当系统发现自己为几个不同的任务开发了类似的程序子程序时，它可以提出一个抽象的、可重用的子程序版本并将其存储在全局库中（见图 14.13）。这些子程序可以是几何的（具有预训练表示的深度学习模块）或算法的（更接近当代软件工程师操作的库）。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 长远愿景\n",
    "\n",
    "模型将更像程序，其功能将远远超出我们目前使用的输入数据的连续几何变换。可以说，这些程序将更接近人类对周围环境和自身保持的抽象心理模型，并且由于其丰富的算法性质，它们将能够进行更强的泛化。\n",
    "\n",
    "特别是，模型将提供正式推理、搜索和抽象能力的算法模块与提供非正式直觉和模式识别能力的几何模块相结合。这将实现以价值为中心和以程序为中心的抽象的混合。 AlphaGo 或自动驾驶汽车（需要大量手动软件工程和人工设计决策的系统）提供了一个早期的例子，说明符号和几何人工智能的混合可能是什么样子。\n",
    "\n",
    "这些模型将自动生成，而不是由人类工程师硬编码，使用存储在可重用子程序的全局库中的模块化部件——该库是通过在数千个以前的任务和数据集上学习高性能模型而发展起来的。由于元学习系统识别出频繁的问题解决模式，它们将变成可重用的子程序——很像软件工程中的函数和类——并添加到全局库中。\n",
    "\n",
    "搜索子程序的可能组合以生成新模型的过程将是一个离散搜索过程（程序综合），但它将受到深度学习提供的程序空间直觉形式的严重指导。\n",
    "\n",
    "这个全局子程序库和相关的模型增长系统将能够实现某种形式的类人极端泛化：给定一个新任务或情况，系统将能够使用很少的数据组装一个适合该任务的新工作模型，多亏了丰富的类似程序的原语可以很好地泛化，以及在类似任务方面的丰富经验。同样，如果人类有许多以前的游戏经验，他们可以很快学会玩一个复杂的新视频游戏，因为从以前的经验中得出的模型是抽象的和程序化的，而不是刺激和动作之间的基本映射。\n",
    "\n",
    "因此，这种不断学习的模型增长系统可以解释为通用人工智能 (AGI)。但不要指望任何奇点机器人末日会随之而来：这纯粹是幻想，来自对智能和技术的一系列深刻误解。然而，这种批评不属于本书。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 在瞬息万变的领域保持最新状态\n",
    "\n",
    "作为最后的告别词，我想给你一些关于如何在你翻完本书的最后一页后继续学习和更新你的知识和技能的建议。 正如我们今天所知，现代深度学习领域只有几年的历史，尽管可以追溯到几十年前的漫长而缓慢的史前时代。 自 2013 年以来，随着财政资源和研究人员数量呈指数级增长，整个领域现在正以疯狂的速度发展。 你在这本书中学到的东西不会永远保持相关性，也不是你职业生涯剩余时间所需要的全部内容。\n",
    "\n",
    "幸运的是，您可以使用大量免费的在线资源来了解最新信息并扩大视野。 这里有一些。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14.6.1 使用 Kaggle 解决实际问题\n",
    "\n",
    "获得现实世界经验的一种有效方法是在 Kaggle (kaggle.com) 上的机器学习竞赛中尝试一下。唯一真正的学习方法是通过实践和实际编码——这就是本书的理念，而 Kaggle 比赛是这一点的自然延续。在 Kaggle 上，你会发现一系列不断更新的数据科学竞赛，其中许多涉及深度学习，由有兴趣获得一些最具挑战性的机器学习问题的新解决方案的公司准备。为顶级参赛者提供相当大的奖金。\n",
    "\n",
    "大多数比赛都是使用 XGBoost 库（用于浅层机器学习）或 Keras（用于深度学习）赢得的。所以你会适合的！通过参加一些比赛，也许作为团队的一员，您将更加熟悉本书中描述的一些高级最佳实践的实践方面，尤其是超参数调整、避免验证集过度拟合和模型集成。\n",
    "14.6.2 阅读关于 arXiv 的最新发展\n",
    "\n",
    "与其他一些科学领域相比，深度学习研究是完全公开的。论文一经定稿就会公开和免费访问，而且许多相关软件都是开源的。 arXiv (arxiv.org) - 发音为“archive”（X 代表希腊语 chi） - 是物理、数学和计算机科学研究论文的开放访问预印本服务器。它已成为了解机器学习和深度学习前沿的事实上的方式。大多数深度学习研究人员在完成后不久将他们写的任何论文上传到 arXiv。这使他们能够在不等待会议接受（需要数月时间）的情况下插上旗帜并声明特定的发现，鉴于研究的快节奏和该领域的激烈竞争，这是必要的。它还允许该领域快速发展：所有新发现都可以立即供所有人查看和建立。\n",
    "\n",
    "一个重要的缺点是，每天在 arXiv 上发布的大量新论文甚至无法全部浏览。由于它们没有经过同行评审，因此很难确定那些既重要又高质量的内容。在噪音中找到信号是一项具有挑战性的工作，而且越来越具有挑战性。但是有些工具可以提供帮助：特别是，您可以使用 Google 学术搜索 (scholar.google.com) 来跟踪您最喜欢的作者的出版物。\n",
    "14.6.3 探索 Keras 生态\n",
    "\n",
    "截至 2021 年初，Keras 拥有约 400,000 名用户且仍在增长，拥有庞大的教程、指南和相关开源项目生态系统：\n",
    "\n",
    "您使用 Keras 的主要参考资料是 keras.io 上的在线文档。特别是，您可以在 keras.io/guides 上找到大量的开发人员指南，在 keras.io/examples 上可以找到数十个高质量的 Keras 代码示例。一定要检查出来！\n",
    "\n",
    "Keras 源代码可以在 github.com/keras-team/keras 找到。\n",
    "\n",
    "您可以在 Keras 邮件列表上寻求帮助并加入深度学习讨论：keras-users@googlegroups.com。\n",
    "你可以在 Twitter 上关注我：@fchollet。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 结束语\n",
    "\n",
    "Python 深度学习到此结束！ 我希望你已经了解了关于机器学习、深度学习、Keras 甚至一般认知的一两件事。 学习是一生的旅程，尤其是在人工智能领域，我们手上的未知数远多于确定性。 所以请继续学习、提问和研究。 永不止步。 因为即使到目前为止取得了进展，人工智能中的大多数基本问题仍然没有答案。 许多人甚至还没有被正确地问过。 "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
