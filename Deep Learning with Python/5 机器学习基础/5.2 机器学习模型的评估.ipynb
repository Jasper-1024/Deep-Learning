{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器学习模型的评估\n",
    "\n",
    "不管是怎样的机器学习的流程,你能控制的永远只有你能见到的东西.机器学习的目标是在前所未见的数据上取得准确的效果.在实现这个目标前,首先需要建立起对模型的评估.\n",
    "\n",
    "大部分方法在前面的内容已经见过了.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练集 验证集 测试集\n",
    "\n",
    "前文的例子中,我们总是将可用数据拆分为 训练集 验证集 测试集\n",
    "\n",
    "- 在验证集上进行模型超参数调整\n",
    "- 在训练集上进行模型训练\n",
    "- 最后在测试集上进行模型评估\n",
    "\n",
    "为什么需要单独分出验证集?\n",
    "\n",
    "- 进行模型训练前,最重要的一环是模型超参数的调整(模型的层数,层的大小,激活函数等等),选择超参数,需要一部分数据验证到底这样选,行不行.这部分数据就是验证集.\n",
    "- 超参数调整虽然不是模型训练,当本质上还是一种学习,验证集的信息 \"泄露\" 到了超参数.如果在使用验证集训练模型,很快会过拟合.\n",
    "  - 为了保证测试模型的效果,测试集的信息一点也不能泄露到模型本身.验证集数据绝对不能和测试集有交集.\n",
    "  - 如果训练集包含验证集样本,这本身会加快过拟合,因此训练集也不能和验证集有交集.(这个不绝对)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 简单留出验证\n",
    "\n",
    "按照比例留出训练集 测试集.简单粗暴.\n",
    "\n",
    "缺点\n",
    "\n",
    "- 样本数量较少,没法进行确切划分\n",
    "- 乱序对结果的影响很大.特别是在样本数量不足时.\n",
    "\n",
    "![holdout_validation](./holdout_validation.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_validation_samples = 10000 # 训练样本数量\n",
    "# np.random.shuffle(data) # 乱序\n",
    "# validation_data = data[:num_validation_samples]#测试集\n",
    "# training_data = data[num_validation_samples:]#训练集\n",
    "# model = get_model()\n",
    "# model.fit(training_data, ...)\n",
    "# validation_score = model.evaluate(validation_data, ...)\n",
    "\n",
    "# ...\n",
    "\n",
    "# model = get_model()\n",
    "# model.fit(np.concatenate([training_data,\n",
    "#                           validation_data]), ...)\n",
    "# test_score = model.evaluate(test_data, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K 折验证\n",
    "\n",
    "将数据分成 K 份,每次在第 i 个分区验证,其他分区训练.一般结果取平均值.\n",
    "\n",
    "如果不同的训练-测试集划分评估结果差异很大,K 折验证能帮上忙.\n",
    "\n",
    "但是与简单留出验证一样,也需要单独的验证集调整超参.\n",
    "\n",
    "![k_fold_validation](./k_fold_validation.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = 3 # 分 3 份\n",
    "# num_validation_samples = len(data) // k #取划分后的数据集的长度\n",
    "# np.random.shuffle(data) # 乱序\n",
    "# validation_scores = []\n",
    "# for fold in range(k):\n",
    "#     validation_data = data[num_validation_samples * fold:\n",
    "#                            num_validation_samples * (fold + 1)] # 测试集\n",
    "#     training_data = np.concatenate(\n",
    "#         data[:num_validation_samples * fold],\n",
    "#         data[num_validation_samples * (fold + 1):]) # 训练集\n",
    "#     model = get_model()\n",
    "#     model.fit(training_data, ...)\n",
    "#     validation_score = model.evaluate(validation_data, ...) # 评估\n",
    "#     validation_scores.append(validation_score) # 存储每次的评估结果\n",
    "# validation_score = np.average(validation_scores)# 平均评估\n",
    "# model = get_model()\n",
    "# model.fit(data, ...)# 训练\n",
    "# test_score = model.evaluate(test_data, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 带有打乱数据的重复 K 折验证\n",
    "\n",
    "如果你的数据很少,但又需要精确评估模型时,上乱序重复 K 折验证.\n",
    "\n",
    "重复多次进行 K 折验证,每次新开始都要将样本重新乱序.\n",
    "\n",
    "这样的代价很高,要训练 P * K 个模型.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 常识性基线\n",
    "\n",
    "虽然并不恰当,训练机器学习模型是一件概率性事件,也不是所有问题都适合机器学习解决.\n",
    "\n",
    "如果机器学习的效果甚至不能打败一个极其简单的解决方案,那这样的模型毫无用途.\n",
    "\n",
    "- mnist 数据集,随机化返回结果准确率 0.1\n",
    "- imdb 数据集,随机结果是 0.5\n",
    "- 二分类问题,如果样本不平衡,那随机分类器的准确度可能还要高.\n",
    "\n",
    "当面对一个前人未解决问题时,一些非常简单的解决方案给定了一个基线.如果机器学习模型连基线都无法达到,此时需要的回退到问题之初重新思考.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 评估模型的其他注意事项\n",
    "\n",
    "数据的代表性\n",
    "\n",
    "- 划分数据集时,随机性要够.否则 mnist 数据集数据按照类别排序,直接取很可能训练集压根没有 89.\n",
    "\n",
    "时间箭头\n",
    "\n",
    "- 所有与预测有关的问题,时间顺序不能打乱.测试集的任何数据都是要晚于训练集的,否则会造成信息的泄露.\n",
    "\n",
    "数据冗余\n",
    "\n",
    "- 数据集中某些样本可能会重复出现,如果恰好一个在训练集,一个在测试集.那完了,测试结果会变好,但是模型没用了.\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aac46f597da82ce9618f0e6f094e6d401f1ab16d9be89acf77ce1dd63d67a333"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('tf': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
