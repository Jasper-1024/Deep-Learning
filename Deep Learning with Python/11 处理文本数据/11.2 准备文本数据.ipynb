{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 11.2 准备文本数据\r\n",
    "\r\n",
    "还是再重复一遍,现有的 nlp 模型只是在文本中提取模型,而不是真正意义上的理解.\r\n",
    "\r\n",
    "如同前面 imdb 数据集的例子,模型无法处理输入的文本,需要将文本转换为数值张量.实现文本到张量的方法很多,但是一般都有相同的步骤.\r\n",
    "\r\n",
    "- 首先是文本标准化,将其转化为小写字母,删除标点符号等.\r\n",
    "- 将文本分割为单元(这个过程称之为标记),例如字符/词/词组等.\r\n",
    "- 将每个这样的标记转成数字张量,通常进行这一步之前,需要将数据中所有标记进行索引.\r\n",
    "\r\n",
    "![from_text_to_vectors](from_text_to_vectors.png)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 文本标准化\r\n",
    "\r\n",
    "考虑下面两个句子\r\n",
    "\r\n",
    "- \"sunset came. i was staring at the Mexico sky. Isnt nature splendid??\"\r\n",
    "- \"Sunset came; I stared at the Mexico sky. Isn’t nature splendid?\"\r\n",
    "\r\n",
    "上面两个句子人读取之后会认为这是几乎一致的两个句子,但是转换成字符串比较看看?\r\n",
    "\r\n",
    "- i 和 I\r\n",
    "- Mexico 和 Mexico 都是墨西哥但是拼写不同\r\n",
    "- Isnt 和 Isn’t\r\n",
    "- stared 和 staring\r\n",
    "\r\n",
    "机器学习无法知道 i 和 I 完全相同,就是大小写区别,é 是带重音的 e.这些规则和常识,机器无法使用,所以需要对文本进行标准化,尽力抹除这样的差异.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\r\n",
    "文本标准化也是特征工程的一种,旨在消除不希望模型处理的编码差异.这个过程并非机器学习独有,其他的工程例如搜索引擎也会进行.\r\n",
    "\r\n",
    "最简单,最广泛的标准化方法: 转换成小写并删除标点符号.在样例上应用.\r\n",
    "\r\n",
    "- \"sunset came i was staring at the mexico sky isnt nature splendid\"\r\n",
    "- \"sunset came i stared at the méxico sky isnt nature splendid\"\r\n",
    "\r\n",
    "比原来接近一些了,还有一种是特殊字符替换.将特殊字符替换为标准字符.这里的就是 e 替代 é,ae 替换 æ 等.\r\n",
    "\r\n",
    "- \"sunset came i was staring at the mexico sky isnt nature splendid\"\r\n",
    "- \"sunset came i stared at the mexico sky isnt nature splendid\"\r\n",
    "\r\n",
    "抹除了一个单词的差异.\r\n",
    "\r\n",
    "还有一种方法是非常高级的标准化,在机器学习背景的 nlp 中更少使用,将术语标准化.将一个术语(一个动词的多种形式/不同连接方式)转换成单一的表示.\r\n",
    "\r\n",
    "- caught 或者 been catching 可以被替换为 catch.\r\n",
    "- cats 可以替换为 cat.\r\n",
    "- was staring 和 stared 可以被替换为 stare.\r\n",
    "\r\n",
    "进行这样的替换,很可能两个意思相近的句子最终会是完全相同的编码.\r\n",
    "\r\n",
    "- \"sunset came i [stare] at the mexico sky isnt nature splendid\"\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "文字标准化后,模型才可能在较少数据量情况下有更好的泛化能力.模型不需要理解 mexico 和 méxico 都是墨西哥,也不需要理会 Sunset 和 sunset 都是日落.当然文字标准化可能会抹除一些信息,(如果是在小说/文章中可能是一些非常精妙的文字描写--私注),所以进行文本标准化要始终看上下文的需要,加入是从采访文章中提取信息,那 `?` 肯定不能直接扔了吧? 必须单独做一个重点标记.\\\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 文本拆分(文本标记化)\r\n",
    "\r\n",
    "\r\n"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('tf')"
  },
  "interpreter": {
   "hash": "aac46f597da82ce9618f0e6f094e6d401f1ab16d9be89acf77ce1dd63d67a333"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}