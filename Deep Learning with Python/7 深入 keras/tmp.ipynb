{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 自定义训练/评估循环(自行实现 fit)\r\n",
    "\r\n",
    "`fit` 在易用性和灵活性之间取得了非常好的平衡,但是这并不意味着 fit 可以适用于任何训练过程.即使 fit 配合自定义指标 自定义损失 自定义回调等,也无法满足全部的训练场景.\r\n",
    "\r\n",
    "`fit` 的工作流只适用于监督学习,监督学习要求数据已经标注,之后通过训练得出模型.然而监督学习只是机器学习的一个大类,还有无监督学习,半监督学习,生成学习,强化学习等等.\r\n",
    "\r\n",
    "如果 fit 无法满足需要,此时就需要编写自己的训练逻辑了.第 2 3 章我们见过一些简单的低层次训练逻辑.一个典型的训练循环如下\r\n",
    "\r\n",
    "- 计算正向传播(人话就是计算模型输出),获取当前批次的损失值.\r\n",
    "- 检索与模型权重有关的损失梯度\r\n",
    "- 更新模型权重,以降低当前批次的损失值.\r\n",
    "\r\n",
    "以上其实就是 fit 做的全部事情,这一节会从头重新实现 fit.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 训练/推理\r\n",
    "\r\n",
    "在 2 3 章的例子中\r\n",
    "\r\n",
    "- 正向传播: `predictions = model(inputs)`\r\n",
    "- 检索与权重相关梯度: `gradients = tape.gradient(loss, model.weights`\r\n",
    "\r\n",
    "编写自定义 fit 这里有两个问题\r\n",
    "\r\n",
    "一些 keras 层在训练和预测之间的行为并不相同.在前向传递调用 keras 模型时,一定要将 `training` 设置为 true.\r\n",
    "\r\n",
    "- 例如 dropout 层在其 `call` 方法中有意训练的 bool 参数,调用 `dropout(inputs, training=True)` 将会忽略一些激活单元,但是调用 `dropout(inputs, training=Flase)` 则不会忽略.\r\n",
    "- 这个参数在 Sequential 或 Functional 生成的模型中也存在.\r\n",
    "\r\n",
    "检索模型的权重梯度时应该使用 `tape.gradients(loss, model.trainable_weights)` 而不是 `tape.gradients(loss, model.weights)`.实际上层和模型有两种类型的权重\r\n",
    "\r\n",
    "- 可训练权重: 可以通过反向传播更新,以最小化模型损失.例如米基础的 kernel 和 bias.\r\n",
    "- 不可训练权重: 前向传递过程中,由层自行维护更新的权重.例如在层增加一个批次计数器.这个信息就会存放在不可训练权重中,每个批次训练时层将计数器 +1.\r\n",
    "\r\n",
    "keras 内置的层中,唯一具有不可训练权重的层是 BatchNormalization ,我们将在第 9 章见到.BatchNormalization 使用不可训练权重跟踪它数据的平均值和标准差,~~进行及时的特征标准化(归一化/规范化).~~(这一句翻译感觉有问题,等到第9章再说).\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "import tensorflow as tf\r\n",
    "import tensorflow.keras as keras\r\n",
    "import tensorflow.keras.layers as layers"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "from tensorflow.keras.datasets import mnist\r\n",
    "(images, labels), (test_images, test_labels) = mnist.load_data()\r\n",
    "images = images.reshape((60000, 28 * 28)).astype(\"float32\") / 255\r\n",
    "test_images = test_images.reshape((10000, 28 * 28)).astype(\"float32\") / 255\r\n",
    "train_images, val_images = images[10000:], images[:10000]\r\n",
    "train_labels, val_labels = labels[10000:], labels[:10000]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def train_step(inputs, targets):\r\n",
    "    with tf.GradientTape() as tape:\r\n",
    "        predictions = model(inputs, training=True)\r\n",
    "        loss = loss_fn(targets, predictions)\r\n",
    "    gradients = tape.gradients(loss, model.trainable_weights)\r\n",
    "    optimizer.apply_gradients(zip(model.trainable_weights, gradients))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 自定义 fit 使用指标\r\n",
    "\r\n",
    "在自定义 fit 的循环中,我们还是想使用 keras 的指标(内置的或者自定义的),前面已经提到过了.\r\n",
    "\r\n",
    "- 更新保存权重 `update_state(y_true, y_pred)`\r\n",
    "- 获取结果 `result()`\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "metric = keras.metrics.SparseCategoricalAccuracy()\r\n",
    "targets = [0, 1, 2]\r\n",
    "predictions = [[1, 0, 0], [0, 1, 0], [0, 0, 1]]\r\n",
    "metric.update_state(targets, predictions)\r\n",
    "current_result = metric.result()\r\n",
    "print(f\"result: {current_result:.2f}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "result: 1.00\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "一个使用指标的示例.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "values = [0, 1, 2, 3, 4]\r\n",
    "mean_tracker = keras.metrics.Mean()\r\n",
    "for value in values:\r\n",
    "    mean_tracker.update_state(value)\r\n",
    "print(f\"Mean of values: {mean_tracker.result():.2f}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mean of values: 2.00\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "跟踪 标量值的均值 -> `keras.metrics.Mean()`\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "最后重置结果 -> `metric.reset_state()`\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 一个完成的训练&评估循环\r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def get_mnist_model():\r\n",
    "    inputs = keras.Input(shape=(28 * 28,))\r\n",
    "    features = layers.Dense(512, activation=\"relu\")(inputs)\r\n",
    "    features = layers.Dropout(0.5)(features)\r\n",
    "    outputs = layers.Dense(10, activation=\"softmax\")(features)\r\n",
    "    model = keras.Model(inputs, outputs)\r\n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "model = get_mnist_model()\r\n",
    "\r\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()  #损失函数\r\n",
    "optimizer = keras.optimizers.RMSprop()  #优化器\r\n",
    "metrics = [keras.metrics.SparseCategoricalAccuracy()]  # 指标\r\n",
    "loss_tracking_metric = keras.metrics.Mean()  #监控均值\r\n",
    "\r\n",
    "\r\n",
    "def train_step(inputs, targets):\r\n",
    "    with tf.GradientTape() as tape:  #正向传播\r\n",
    "        predictions = model(inputs, training=True)  #training = true\r\n",
    "        loss = loss_fn(targets, predictions)  #损失\r\n",
    "    # 反向传播\r\n",
    "    gradients = tape.gradient(loss, model.trainable_weights)\r\n",
    "    optimizer.apply_gradients(zip(gradients,\r\n",
    "                                  model.trainable_weights))  #优化器更新权重\r\n",
    "\r\n",
    "    logs = {}\r\n",
    "    for metric in metrics:  #指标\r\n",
    "        metric.update_state(targets, predictions)\r\n",
    "        logs[metric.name] = metric.result()  #获取指标结果\r\n",
    "\r\n",
    "    loss_tracking_metric.update_state(loss)  #损失均值\r\n",
    "    logs[\"loss\"] = loss_tracking_metric.result()\r\n",
    "    return logs  #返回结果\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "一个完成的训练/评估循环.接收数据训练,返回 ift 进度条日志.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "def reset_metrics():  #重置指标\r\n",
    "    for metric in metrics:\r\n",
    "        metric.reset_states()\r\n",
    "    loss_tracking_metric.reset_states()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "每个 epoch 我们都需要重置指标\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "training_dataset = tf.data.Dataset.from_tensor_slices(\r\n",
    "    (train_images, train_labels))  #张量化\r\n",
    "training_dataset = training_dataset.batch(32)  #一个批次长度 32\r\n",
    "epochs = 3  #3轮 ephoch\r\n",
    "for epoch in range(epochs):\r\n",
    "    reset_metrics()  #重置指标\r\n",
    "    for inputs_batch, targets_batch in training_dataset:  #训练\r\n",
    "        logs = train_step(inputs_batch, targets_batch)\r\n",
    "    print(f\"Results at the end of epoch {epoch}\")  #打印结果\r\n",
    "    for key, value in logs.items():\r\n",
    "        print(f\"...{key}: {value:.4f}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Results at the end of epoch 0\n",
      "...sparse_categorical_accuracy: 0.9138\n",
      "...loss: 0.2901\n",
      "Results at the end of epoch 1\n",
      "...sparse_categorical_accuracy: 0.9528\n",
      "...loss: 0.1679\n",
      "Results at the end of epoch 2\n",
      "...sparse_categorical_accuracy: 0.9627\n",
      "...loss: 0.1389\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "自定义训练流程.这里使用了 `tf.data.Dataset` 将传入数据拆分成了 32 尺寸的批次."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "def test_step(inputs, targets):  #和训练循环差不多,省略了反向传播和权重更新\r\n",
    "    predictions = model(inputs, training=False)  #评估阶段 预测值,training = false\r\n",
    "    loss = loss_fn(targets, predictions)  #损失\r\n",
    "\r\n",
    "    logs = {}\r\n",
    "    for metric in metrics:  #指标\r\n",
    "        metric.update_state(targets, predictions)\r\n",
    "        logs[\"val_\" + metric.name] = metric.result()  #预测值结果\r\n",
    "\r\n",
    "    loss_tracking_metric.update_state(loss)\r\n",
    "    logs[\"val_loss\"] = loss_tracking_metric.result()\r\n",
    "    return logs\r\n",
    "\r\n",
    "\r\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices(\r\n",
    "    (val_images, val_labels))  #张量化\r\n",
    "val_dataset = val_dataset.batch(32)  #拆分尺寸 32\r\n",
    "reset_metrics()\r\n",
    "for inputs_batch, targets_batch in val_dataset:\r\n",
    "    logs = test_step(inputs_batch, targets_batch)\r\n",
    "print(\"Evaluation results:\")\r\n",
    "for key, value in logs.items():  #取均值\r\n",
    "    print(f\"...{key}: {value:.4f}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Evaluation results:\n",
      "...val_sparse_categorical_accuracy: 0.9688\n",
      "...val_loss: 0.1233\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "至此我们终于实现了和 fit 与 evaluation 差不多的基础功能.当然 fit 和 evaluation 还支持更多更复杂功能.\r\n",
    "\r\n",
    "别急还没结束,还有性能优化.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 使用 `tf.function` 注解加速\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "@tf.function\r\n",
    "def test_step(inputs, targets):\r\n",
    "    predictions = model(inputs, training=False)\r\n",
    "    loss = loss_fn(targets, predictions)\r\n",
    "\r\n",
    "    logs = {}\r\n",
    "    for metric in metrics:\r\n",
    "        metric.update_state(targets, predictions)\r\n",
    "        logs[\"val_\" + metric.name] = metric.result()\r\n",
    "\r\n",
    "    loss_tracking_metric.update_state(loss)\r\n",
    "    logs[\"val_loss\"] = loss_tracking_metric.result()\r\n",
    "    return logs\r\n",
    "\r\n",
    "\r\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\r\n",
    "val_dataset = val_dataset.batch(32)\r\n",
    "reset_metrics()\r\n",
    "for inputs_batch, targets_batch in val_dataset:\r\n",
    "    logs = test_step(inputs_batch, targets_batch)\r\n",
    "print(\"Evaluation results:\")\r\n",
    "for key, value in logs.items():\r\n",
    "    print(f\"...{key}: {value:.4f}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Evaluation results:\n",
      "...val_sparse_categorical_accuracy: 0.9688\n",
      "...val_loss: 0.1233\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "直接编写的 test_step 执行时会如同所有 python 代码一样,逐行执行,方便调试.但是这样从性能角度并不划算.\r\n",
    "\r\n",
    "简单添加 `@tf.function` 就能使得 tensorflow 单独编译这个函数,基本加速了一倍差不多(cpu).\r\n",
    "\r\n",
    "但是编码/调试阶段不要乱用,`@tf.function` 会干扰调试找 bug.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 带有 fit 的自定义训练循环\r\n",
    "\r\n",
    "完全重新函数实现 fit 的功能,耗时耗力,灵活性高,但是无法使用 fit 的各种便利的功能.\r\n",
    "\r\n",
    "实际上在使用 fit 和完全自定义训练循环之外,还有一个中间地带.可以编写自定义的训练步骤,再让 fit 完成其他工作.\r\n",
    "\r\n",
    "覆盖 Model 的 `train_step`方法,这个方法是 fit 为每轮数据调用的训练方法.就像是偷偷替换了汽车引擎,但是 fit 完全不知道,还在跑."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()  #损失函数\r\n",
    "loss_tracker = keras.metrics.Mean(name=\"loss\")  #监控均值\r\n",
    "\r\n",
    "\r\n",
    "class CustomModel(keras.Model):\r\n",
    "    def train_step(self, data):  #覆盖训练函数\r\n",
    "        inputs, targets = data\r\n",
    "        with tf.GradientTape() as tape:  #正向传播\r\n",
    "            predictions = self(inputs, training=True)\r\n",
    "            loss = loss_fn(targets, predictions)\r\n",
    "        gradients = tape.gradient(loss, model.trainable_weights)  #反向传播\r\n",
    "        optimizer.apply_gradients(zip(gradients,\r\n",
    "                                      model.trainable_weights))  #优化器更新权重\r\n",
    "\r\n",
    "        loss_tracker.update_state(loss)  #更新均值\r\n",
    "        return {\"loss\": loss_tracker.result()}  #返回字典\r\n",
    "\r\n",
    "    @property\r\n",
    "    def metrics(self):#指标\r\n",
    "        return [loss_tracker]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "子类 CustomModel\r\n",
    "\r\n",
    "- 覆盖了 train_step 方法,训练循环几乎和上一小节一致.\r\n",
    "- 最终返回一个结果字典\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "inputs = keras.Input(shape=(28 * 28, ))\r\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\r\n",
    "features = layers.Dropout(0.5)(features)\r\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\r\n",
    "model = CustomModel(inputs, outputs)  #模型实例化\r\n",
    "\r\n",
    "model.compile(optimizer=keras.optimizers.RMSprop())\r\n",
    "model.fit(train_images, train_labels, epochs=3)  #训练\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.2984\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 0.1662\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.1416\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a557358550>"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "覆盖过 `train_step` 的类实例化,并不妨碍其与其他模型组合.\r\n",
    "\r\n",
    "覆盖 `train_step` 不需要 `@tf.function` 注解,框架会自动进行优化."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class CustomModel(keras.Model):\r\n",
    "    def train_step(self, data):\r\n",
    "        inputs, targets = data\r\n",
    "        with tf.GradientTape() as tape:\r\n",
    "            predictions = self(inputs, training=True)\r\n",
    "            loss = self.compiled_loss(targets, predictions)  #计算损失\r\n",
    "        gradients = tape.gradient(loss, model.trainable_weights)\r\n",
    "        optimizer.apply_gradients(zip(gradients,\r\n",
    "                                      model.trainable_weights))  #优化器更新权重\r\n",
    "        self.compiled_metrics.update_state(targets, predictions)  #更新指标\r\n",
    "        return {m.name: m.result() for m in self.metrics}  #实际返回的指标列表\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "上面的例子有一点不好,优化器/损失函数/指标是在 `train_step` 定义的.实际上在 model 调用 `model.compile` 后,在 `train_step` 是可以访问到传入的优化器/损失函数/指标的\r\n",
    "\r\n",
    "- self.compiled_loss 损失函数\r\n",
    "- self.compiled_metrics 指标列表的封装,可以调用 `self.compiled_metrics.update_state` 一次性更新全部指标.\r\n",
    "- self.metrics 传递给 compile 的实际指标列表.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "inputs = keras.Input(shape=(28 * 28, ))\r\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\r\n",
    "features = layers.Dropout(0.5)(features)\r\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\r\n",
    "model = CustomModel(inputs, outputs)\r\n",
    "\r\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(),\r\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(),\r\n",
    "              metrics=[keras.metrics.SparseCategoricalAccuracy()])\r\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 17s 10ms/step - loss: 0.2972\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 0.1635\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.1404\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a55cac5d90>"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "while 以上就是这本书需要用到的全部 keras api.现在你应该能做一些之前做不到的事情了.\r\n"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('tf': venv)"
  },
  "interpreter": {
   "hash": "aac46f597da82ce9618f0e6f094e6d401f1ab16d9be89acf77ce1dd63d67a333"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}